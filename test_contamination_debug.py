#!/usr/bin/env python3
"""
Script de test pour analyser le problÃ¨me de dÃ©tection de contamination
"""

import sys
import os
import logging

# Ajouter le dossier api au path
sys.path.append(os.path.join(os.path.dirname(__file__), 'api'))

from models.vision_model import VisionModel

# Configuration du logging pour voir tous les dÃ©tails
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def test_contamination_image():
    """Test avec l'image problÃ©matique"""
    
    # Chemin vers l'image avec contamination
    image_path = "api/images_a_traiter/4d17b151-36ae-4e30-b01c-8998087d4497.jpeg"
    
    if not os.path.exists(image_path):
        print(f"âŒ Image non trouvÃ©e: {image_path}")
        return
    
    print(f"ğŸ” Test avec l'image: {image_path}")
    print("=" * 60)
    
    # Initialiser le modÃ¨le
    try:
        model = VisionModel()
        print("âœ… VisionModel initialisÃ©")
        
        # Charger le modÃ¨le
        if not model.load_model():
            print("âŒ Impossible de charger le modÃ¨le")
            return
        
        print(f"âœ… ModÃ¨le chargÃ©: {model.model_type}")
        print(f"ğŸ“ Taille d'entrÃ©e: {model.input_size}")
        print(f"ğŸ·ï¸ Classes: {model.class_names}")
        
        # Effectuer la prÃ©diction
        print("\nğŸš€ Lancement de la prÃ©diction...")
        result = model.predict(image_path)
        
        # Afficher les rÃ©sultats dÃ©taillÃ©s
        print("\nğŸ“Š RÃ‰SULTATS DÃ‰TAILLÃ‰S:")
        print("=" * 60)
        print(f"ğŸ† PrÃ©diction finale: {result['prediction']}")
        print(f"ğŸ“ˆ Confiance: {result['confidence']:.3f} ({result['confidence']*100:.1f}%)")
        print(f"â˜ ï¸ ProbabilitÃ© contamination: {result.get('contamination_probability', 'N/A'):.3f}")
        
        if 'detection_summary' in result:
            summary = result['detection_summary']
            print(f"\nğŸ” RÃ‰SUMÃ‰ DES DÃ‰TECTIONS:")
            print(f"  ğŸ“Š Total dÃ©tections: {summary['total_detections']}")
            print(f"  â˜ ï¸ Objets contaminÃ©s: {summary['contaminated_count']}")
            print(f"  âœ… Objets sains: {summary['healthy_count']}")
            print(f"  ğŸ“ˆ Meilleur score contaminÃ©: {summary['max_contaminated_score']:.3f}")
            print(f"  ğŸ“ˆ Meilleur score sain: {summary['max_healthy_score']:.3f}")
            
        if 'detections' in result:
            print(f"\nğŸ¯ DÃ‰TECTIONS INDIVIDUELLES ({len(result['detections'])}):")
            for i, detection in enumerate(result['detections']):
                print(f"  {i+1}. {detection['class_name']} - Score: {detection['score']:.3f}")
                print(f"     Box: {[f'{x:.3f}' for x in detection['box']]}")
        
        # Diagnostic du problÃ¨me
        print("\nğŸ©º DIAGNOSTIC:")
        print("=" * 60)
        
        if result['prediction'] == 'sain' and result.get('contamination_probability', 0) < 0.5:
            if result.get('detection_summary', {}).get('healthy_count', 0) > 0:
                max_healthy = result.get('detection_summary', {}).get('max_healthy_score', 0)
                if max_healthy < 0.7:
                    print("âš ï¸ PROBLÃˆME DÃ‰TECTÃ‰: Objets classÃ©s 'sains' mais avec des scores modÃ©rÃ©s")
                    print(f"   Le meilleur score 'sain' est de {max_healthy:.3f} (< 0.7)")
                    print("   Cela pourrait indiquer une contamination non dÃ©tectÃ©e")
                else:
                    print("âœ… Classification correcte: objets vraiment sains avec bons scores")
            else:
                print("âš ï¸ Aucun objet dÃ©tectÃ© - difficile de juger la qualitÃ©")
        elif result['prediction'] == 'contamine':
            print("âœ… Contamination dÃ©tectÃ©e correctement")
        else:
            print("â“ PrÃ©diction incertaine - nÃ©cessite investigation")
        
    except Exception as e:
        print(f"âŒ Erreur lors du test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_contamination_image()
