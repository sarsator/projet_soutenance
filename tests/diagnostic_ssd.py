#!/usr/bin/env python3
"""
Script de diagnostic du mod√®le SSD pour comprendre pourquoi il ne d√©tecte rien
"""
import sys
sys.path.append('/home/sarsator/projets/gaia_vision')

import tensorflow as tf
import numpy as np
from PIL import Image
from pathlib import Path
import json

def test_ssd_raw():
    """Test direct du mod√®le SSD pour voir ses sorties brutes"""
    
    # Charger le mod√®le
    model_path = Path("/home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518/saved_model")
    
    print("üîç DIAGNOSTIC DU MOD√àLE SSD")

    print(f"Chemin du mod√®le: {model_path}")
    
    try:
        # Charger le SavedModel
        model = tf.saved_model.load(str(model_path))
        print("‚úÖ Mod√®le charg√©")
        
        # Charger une image de test
        image_path = "/home/sarsator/projets/gaia_vision/api/images_a_traiter/01640b85-29ca-4cb6-b8dc-26264ee26008.jpg"
        img = Image.open(image_path)
        img = img.convert('RGB')
        img = img.resize((320, 320))
        
        # Pr√©processer
        img_array = np.array(img, dtype=np.uint8)
        img_tensor = tf.convert_to_tensor(img_array)
        img_tensor = tf.expand_dims(img_tensor, 0)
        
        print(f"Image pr√©process√©e: shape={img_tensor.shape}, dtype={img_tensor.dtype}")
        
        # Pr√©diction
        infer = model.signatures['serving_default']
        predictions = infer(input_tensor=img_tensor)
        
        # Analyser toutes les sorties
        detection_boxes = predictions['detection_boxes'].numpy()[0]
        detection_classes = predictions['detection_classes'].numpy()[0]
        detection_scores = predictions['detection_scores'].numpy()[0]
        num_detections = int(predictions['num_detections'].numpy()[0])
        
        print(f"\nüìä R√âSULTATS BRUTS:")
        print(f"Nombre de d√©tections: {num_detections}")
        print(f"Scores max: {np.max(detection_scores):.4f}")
        print(f"Scores min: {np.min(detection_scores):.4f}")
        print(f"Scores moyens: {np.mean(detection_scores):.4f}")
        
        # Analyser par seuils
        seuils = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
        
        print(f"\nüéØ ANALYSE PAR SEUILS:")
        for seuil in seuils:
            detections_valides = sum(1 for score in detection_scores if score > seuil)
            print(f"Seuil {seuil}: {detections_valides} d√©tections")
        
        # D√©tailler les 10 meilleures d√©tections
        print(f"\nüèÜ TOP 10 D√âTECTIONS:")
        indices_sorted = np.argsort(detection_scores)[::-1][:10]
        
        for i, idx in enumerate(indices_sorted):
            score = detection_scores[idx]
            class_id = int(detection_classes[idx])
            box = detection_boxes[idx]
            
            class_names = ["background", "healthy", "contaminated"]
            class_name = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
            
            print(f"  {i+1:2d}. Score: {score:.4f} | Classe: {class_name} ({class_id}) | Box: [{box[0]:.3f}, {box[1]:.3f}, {box[2]:.3f}, {box[3]:.3f}]")
        
        # Test avec diff√©rentes classes
        print(f"\nüî¢ R√âPARTITION PAR CLASSES:")
        for class_id in [0, 1, 2]:
            class_detections = sum(1 for cls in detection_classes if int(cls) == class_id)
            class_scores = [detection_scores[i] for i, cls in enumerate(detection_classes) if int(cls) == class_id]
            max_score = max(class_scores) if class_scores else 0
            
            class_names = ["background", "healthy", "contaminated"]
            class_name = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
            
            print(f"  Classe {class_id} ({class_name}): {class_detections} d√©tections, score max: {max_score:.4f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_ssd_raw()
