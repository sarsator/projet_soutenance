{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09274ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration CORRIGÉE:\n",
      "   Modèle: SSD MobileNet V2 320x320 (COMPATIBLE TF 2.15)\n",
      "   Image size: 320x320\n",
      "   Batch size: 16\n",
      "   Training steps: 30,000\n",
      "   Output directory: ../models/dl_model/outputs/ssd_mnv2_320\n",
      "   Tracking: tensorboard\n",
      "   ✅ Ce modèle va FONCTIONNER avec TensorFlow 2.15 !\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "# Config centralisée - modifie ici, tout le reste suit !\n",
    "IMG_SIZE         = 320          # côté carré des images (320 pour le checkpoint)\n",
    "BATCH_SIZE       = 16           # RTX 4080 = large marge\n",
    "NUM_STEPS        = 30000        # ≈ 40 epochs (peut ↓/↑)\n",
    "BASE_LR          = 0.02         # LR de départ (cosine schedule)\n",
    "WARMUP_STEPS     = int(0.05*NUM_STEPS)\n",
    "\n",
    "TRAIN_DIR        = \"../data/DL_data/train\"\n",
    "VAL_DIR          = \"../data/DL_data/valid\"\n",
    "\n",
    "TRAIN_ANN        = f\"{TRAIN_DIR}/_annotations.csv\"\n",
    "VAL_ANN          = f\"{VAL_DIR}/_annotations.csv\"\n",
    "\n",
    "# MODÈLE COMPATIBLE TF 2.15: SSD MobileNet V2 Keras\n",
    "PRETRAIN_CKPT    = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "OUTPUT_DIR       = \"../models/dl_model/outputs/ssd_mnv2_320\"\n",
    "LABEL_MAP        = f\"{OUTPUT_DIR}/label_map.pbtxt\"\n",
    "TFRECORD_TRAIN   = f\"{OUTPUT_DIR}/train.record\"\n",
    "TFRECORD_VAL     = f\"{OUTPUT_DIR}/val.record\"\n",
    "\n",
    "TRACKING         = \"tensorboard\"  # (tensorboard / wandb / mlflow)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "print(f\"📋 Configuration CORRIGÉE:\")\n",
    "print(f\"   Modèle: SSD MobileNet V2 320x320 (COMPATIBLE TF 2.15)\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Training steps: {NUM_STEPS:,}\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"   Tracking: {TRACKING}\")\n",
    "print(f\"   ✅ Ce modèle va FONCTIONNER avec TensorFlow 2.15 !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b48a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:20:34.507415: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 00:20:34.526298: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 00:20:34.526319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 00:20:34.526973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 00:20:34.531197: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-16 00:20:35.035026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-16 00:20:35.035026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 TensorFlow version: 2.15.0\n",
      "🎮 GPUs détectés: 1\n",
      "   GPU 0: /physical_device:GPU:0\n",
      "🚀 GPU unique activé\n",
      "✅ Configuration GPU terminée\n",
      "\n",
      "🧪 Test de calcul GPU...\n",
      "✅ Calcul effectué sur: device:GPU:0\n",
      "✅ Répertoire de sortie créé: ../models/dl_model/outputs/ssd_mnv2_320\n",
      "✅ Checkpoint déjà présent: ../models/dl_model/outputs/ssd_mnv2_320/pretrained_checkpoint\n",
      "📍 Chemin du checkpoint: ../models/dl_model/outputs/ssd_mnv2_320/pretrained_checkpoint/checkpoint/ckpt-0\n",
      "\n",
      "📋 Résumé de la configuration:\n",
      "   🎮 Device: GPU\n",
      "   🔢 Nombre de GPUs: 1\n",
      "   📏 Batch size: 16\n",
      "   🖼️  Image size: 512x512\n",
      "   🤖 Modèle: SSD MobileNet V2 320x320\n",
      "   ⚡ Estimation RTX 4080: ~2-3h pour 30,000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:20:35.441606: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.481552: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.481588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.483865: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.483894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.483906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.611504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.611547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.611553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-07-16 00:20:35.611573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 00:20:35.611592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13512 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:02:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"🔧 TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🎮 DETECTION ET CONFIGURATION GPU\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "# Vérification de la disponibilité des GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f\"🎮 GPUs détectés: {len(gpus)}\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configuration pour permettre la croissance de mémoire\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Affichage des détails des GPUs\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   GPU {i}: {gpu.name}\")\n",
    "            \n",
    "        # Configuration de la stratégie de distribution si multiple GPUs\n",
    "        if len(gpus) > 1:\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "            print(f\"🚀 Multi-GPU activé: {strategy.num_replicas_in_sync} GPUs\")\n",
    "        else:\n",
    "            strategy = tf.distribute.get_strategy()  # Stratégie par défaut\n",
    "            print(f\"🚀 GPU unique activé\")\n",
    "            \n",
    "        print(f\"✅ Configuration GPU terminée\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(f\"❌ Erreur de configuration GPU: {e}\")\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    print(\"⚠️  Aucun GPU détecté - Entraînement CPU (très lent!)\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# Test rapide de calcul GPU\n",
    "print(\"\\n🧪 Test de calcul GPU...\")\n",
    "with tf.device('/GPU:0' if gpus else '/CPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    device_name = c.device.split('/')[-1]\n",
    "    print(f\"✅ Calcul effectué sur: {device_name}\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "# Création du répertoire de sortie\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"✅ Répertoire de sortie créé: {OUTPUT_DIR}\")\n",
    "\n",
    "# Téléchargement et extraction du checkpoint pré-entraîné CORRECT\n",
    "checkpoint_dir = f\"{OUTPUT_DIR}/pretrained_checkpoint\"\n",
    "checkpoint_url = PRETRAIN_CKPT\n",
    "checkpoint_tar = f\"{OUTPUT_DIR}/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    print(f\"📥 Téléchargement du checkpoint MobileNet V2 correct...\")\n",
    "    \n",
    "    # URL du bon modèle MobileNet V2\n",
    "    checkpoint_urls = [\n",
    "        PRETRAIN_CKPT,  # URL configurée dans la cellule 1\n",
    "        \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\"\n",
    "    ]\n",
    "    \n",
    "    download_success = False\n",
    "    for i, url in enumerate(checkpoint_urls):\n",
    "        try:\n",
    "            print(f\"   📡 Tentative {i+1}: {url.split('/')[-1]}\")\n",
    "            urllib.request.urlretrieve(url, checkpoint_tar)\n",
    "            download_success = True\n",
    "            print(f\"   ✅ Téléchargement réussi!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Échec tentative {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if download_success:\n",
    "        print(f\"📦 Extraction du checkpoint...\")\n",
    "        with tarfile.open(checkpoint_tar, 'r:gz') as tar:\n",
    "            tar.extractall(OUTPUT_DIR)\n",
    "        \n",
    "        # Renommer le dossier extrait (nom correct pour MobileNet V2)\n",
    "        extracted_name = \"ssd_mobilenet_v2_320x320_coco17_tpu-8\"\n",
    "        if os.path.exists(f\"{OUTPUT_DIR}/{extracted_name}\"):\n",
    "            shutil.move(f\"{OUTPUT_DIR}/{extracted_name}\", checkpoint_dir)\n",
    "        \n",
    "        # Nettoyer le fichier tar\n",
    "        os.remove(checkpoint_tar)\n",
    "        print(f\"✅ Checkpoint MobileNet V2 téléchargé et extrait dans: {checkpoint_dir}\")\n",
    "        \n",
    "        CHECKPOINT_PATH = f\"{checkpoint_dir}/checkpoint/ckpt-0\"\n",
    "    else:\n",
    "        print(f\"❌ Échec de toutes les tentatives de téléchargement\")\n",
    "        print(f\"💡 Solution manuelle:\")\n",
    "        print(f\"   wget {checkpoint_urls[0]} -O {checkpoint_tar}\")\n",
    "        print(f\"   tar -xzf {checkpoint_tar} -C {OUTPUT_DIR}\")\n",
    "        \n",
    "        # Créer un checkpoint factice temporaire\n",
    "        os.makedirs(f\"{checkpoint_dir}/checkpoint\", exist_ok=True)\n",
    "        CHECKPOINT_PATH = f\"{checkpoint_dir}/checkpoint/ckpt-0\"\n",
    "else:\n",
    "    print(f\"✅ Checkpoint déjà présent: {checkpoint_dir}\")\n",
    "    CHECKPOINT_PATH = f\"{checkpoint_dir}/checkpoint/ckpt-0\"\n",
    "print(f\"📍 Chemin du checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "# Affichage du résumé de configuration\n",
    "print(f\"\\n📋 Résumé de la configuration:\")\n",
    "print(f\"   🎮 Device: {'GPU' if gpus else 'CPU'}\")\n",
    "print(f\"   🔢 Nombre de GPUs: {len(gpus)}\")\n",
    "print(f\"   📏 Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   🖼️  Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   🤖 Modèle: SSD MobileNet V2 320x320\")\n",
    "if gpus:\n",
    "    print(f\"   ⚡ Estimation RTX 4080: ~2-3h pour {NUM_STEPS:,} steps\")\n",
    "else:\n",
    "    print(f\"   🐌 Estimation CPU: ~20-30h pour {NUM_STEPS:,} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5818592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Correction de l'incompatibilité tf-slim/TensorFlow 2.15...\n",
      "❌ Détection du bug tf-slim : control_flow_ops.case manquant\n",
      "✅ Patch appliqué : control_flow_ops.case restauré\n",
      "💡 tf-slim va maintenant fonctionner avec TensorFlow 2.15\n",
      "🎯 Correction tf-slim terminée\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🔧 CORRECTION INCOMPATIBILITÉ TF-SLIM / TENSORFLOW 2.15\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"🔧 Correction de l'incompatibilité tf-slim/TensorFlow 2.15...\")\n",
    "\n",
    "# Le problème : tf-slim utilise control_flow_ops.case qui n'existe plus dans TF 2.15\n",
    "# Solution : Utiliser une version compatible ou patcher\n",
    "\n",
    "try:\n",
    "    # Test si le problème existe\n",
    "    from tensorflow.python.ops import control_flow_ops\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    patches_applied = []\n",
    "    \n",
    "    # Patch pour control_flow_ops.case\n",
    "    if not hasattr(control_flow_ops, 'case'):\n",
    "        def case_wrapper(pred_fn_pairs, default=None, exclusive=False, name='case'):\n",
    "            \"\"\"Wrapper pour remplacer control_flow_ops.case\"\"\"\n",
    "            return tf.case(pred_fn_pairs, default=default, exclusive=exclusive, name=name)\n",
    "        \n",
    "        control_flow_ops.case = case_wrapper\n",
    "        patches_applied.append(\"case\")\n",
    "    \n",
    "    # Patch pour control_flow_ops.cond \n",
    "    if not hasattr(control_flow_ops, 'cond'):\n",
    "        def cond_wrapper(pred, true_fn=None, false_fn=None, name=None):\n",
    "            \"\"\"Wrapper pour remplacer control_flow_ops.cond\"\"\"\n",
    "            return tf.cond(pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
    "        \n",
    "        control_flow_ops.cond = cond_wrapper\n",
    "        patches_applied.append(\"cond\")\n",
    "        \n",
    "    # Patch pour control_flow_ops.while_loop si nécessaire\n",
    "    if not hasattr(control_flow_ops, 'while_loop'):\n",
    "        def while_loop_wrapper(cond, body, loop_vars, shape_invariants=None, \n",
    "                              parallel_iterations=10, back_prop=True, \n",
    "                              swap_memory=False, name=None, maximum_iterations=None,\n",
    "                              return_same_structure=False):\n",
    "            \"\"\"Wrapper pour remplacer control_flow_ops.while_loop\"\"\"\n",
    "            return tf.while_loop(\n",
    "                cond=cond, body=body, loop_vars=loop_vars,\n",
    "                shape_invariants=shape_invariants, \n",
    "                parallel_iterations=parallel_iterations,\n",
    "                back_prop=back_prop, swap_memory=swap_memory, \n",
    "                name=name, maximum_iterations=maximum_iterations,\n",
    "                return_same_structure=return_same_structure\n",
    "            )\n",
    "        \n",
    "        control_flow_ops.while_loop = while_loop_wrapper\n",
    "        patches_applied.append(\"while_loop\")\n",
    "    \n",
    "    if patches_applied:\n",
    "        print(f\"❌ Détection du bug tf-slim : {', '.join(patches_applied)} manquant(s)\")\n",
    "        print(f\"✅ Patch appliqué : {', '.join(patches_applied)} restauré(s)\")\n",
    "        print(\"💡 tf-slim va maintenant fonctionner avec TensorFlow 2.15\")\n",
    "    else:\n",
    "        print(\"✅ tf-slim compatible - Aucune correction nécessaire\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"⚠️  Erreur d'import: {e}\")\n",
    "    print(\"💡 Continuons - le patch sera appliqué si nécessaire\")\n",
    "\n",
    "print(\"🎯 Correction tf-slim terminée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ad505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label map créé: ../models/dl_model/outputs/ssd_mnv2_320/label_map.pbtxt\n",
      "🏷️ Classes:\n",
      "   1: Healthy\n",
      "   2: Contaminated\n"
     ]
    }
   ],
   "source": [
    "# Création du label map\n",
    "label_map_content = \"\"\"item {\n",
    "  id: 1\n",
    "  name: 'Healthy'\n",
    "}\n",
    "item {\n",
    "  id: 2\n",
    "  name: 'Contaminated'\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(LABEL_MAP, 'w') as f:\n",
    "    f.write(label_map_content)\n",
    "\n",
    "print(f\"✅ Label map créé: {LABEL_MAP}\")\n",
    "print(\"🏷️ Classes:\")\n",
    "print(\"   1: Healthy\")\n",
    "print(\"   2: Contaminated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17443a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Vérification des fichiers requis...\n",
      "✅ Tous les fichiers requis existent\n",
      "\n",
      "🔍 État des fichiers TFRecord (CORRIGÉ):\n",
      "   ✅ TFRecord train existe: ../models/dl_model/outputs/ssd_mnv2_320/train.record (4669.5 MB)\n",
      "   ✅ TFRecord validation existe: ../models/dl_model/outputs/ssd_mnv2_320/val.record (302.0 MB)\n",
      "\n",
      "⏭️  TFRecord d'entraînement déjà existant - Conversion ignorée\n",
      "\n",
      "⏭️  TFRecord de validation déjà existant - Conversion ignorée\n",
      "\n",
      "📈 Résumé final:\n",
      "   Train: 16787 boîtes, 9186 images\n",
      "   Valid: 1006 boîtes, 743 images\n",
      "   Total: 17793 boîtes, 9929 images\n",
      "\n",
      "💡 Optimisation: Aucune conversion nécessaire - Fichiers déjà prêts!\n",
      "   ⚡ Temps économisé: ~2-3 minutes de conversion évitées\n",
      "   🎯 BUG DE TAILLE CORRIGÉ - Les gros fichiers sont maintenant acceptés!\n"
     ]
    }
   ],
   "source": [
    "def create_tf_example(row, img_dir):\n",
    "    \"\"\"Crée un tf.train.Example pour une ligne du CSV\"\"\"\n",
    "    \n",
    "    # Chemins des fichiers\n",
    "    img_path = os.path.join(img_dir, row['filename'])\n",
    "    \n",
    "    # Vérification de l'existence de l'image\n",
    "    if not os.path.exists(img_path):\n",
    "        raise FileNotFoundError(f\"Image introuvable: {img_path}\")\n",
    "    \n",
    "    # Lecture de l'image\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_image = fid.read()\n",
    "    \n",
    "    # Obtenir les dimensions de l'image\n",
    "    image = tf.image.decode_image(encoded_image)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Validation des dimensions\n",
    "    if height != row['height'] or width != row['width']:\n",
    "        print(f\"⚠️  Dimensions incohérentes pour {row['filename']}: CSV({row['width']}x{row['height']}) vs Image({width}x{height})\")\n",
    "    \n",
    "    # Normalisation des coordonnées (0-1)\n",
    "    xmin_norm = row['xmin'] / width\n",
    "    xmax_norm = row['xmax'] / width\n",
    "    ymin_norm = row['ymin'] / height\n",
    "    ymax_norm = row['ymax'] / height\n",
    "    \n",
    "    # Mapping des classes\n",
    "    class_mapping = {'Healthy': 1, 'Contaminated': 2}\n",
    "    class_id = class_mapping.get(row['class'])\n",
    "    if class_id is None:\n",
    "        raise ValueError(f\"Classe inconnue: {row['class']}\")\n",
    "    \n",
    "    # Création de l'exemple TF\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['filename'].encode('utf8')])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['filename'].encode('utf8')])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'jpeg'])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=[xmin_norm])),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=[xmax_norm])),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=[ymin_norm])),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=[ymax_norm])),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['class'].encode('utf8')])),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=[class_id])),\n",
    "    }))\n",
    "    \n",
    "    return tf_example\n",
    "\n",
    "def convert_csv_to_tfrecord(csv_path, img_dir, output_path):\n",
    "    \"\"\"Convertit un CSV en TFRecord\"\"\"\n",
    "    \n",
    "    print(f\"📊 Lecture du CSV: {csv_path}\")\n",
    "    \n",
    "    # Lecture du CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Vérification des colonnes requises\n",
    "    required_cols = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Colonnes manquantes dans le CSV: {missing_cols}\")\n",
    "    \n",
    "    # Vérification des valeurs NaN\n",
    "    if df.isnull().any().any():\n",
    "        print(\"⚠️  Valeurs NaN détectées dans le CSV:\")\n",
    "        print(df.isnull().sum())\n",
    "        raise ValueError(\"Le CSV contient des valeurs NaN\")\n",
    "    \n",
    "    # Écriture du TFRecord\n",
    "    print(f\"✍️  Écriture du TFRecord: {output_path}\")\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        total_boxes = 0\n",
    "        unique_images = set()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                tf_example = create_tf_example(row, img_dir)\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "                total_boxes += 1\n",
    "                unique_images.add(row['filename'])\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur pour {row['filename']}: {e}\")\n",
    "                raise\n",
    "    \n",
    "    print(f\"✅ TFRecord créé avec succès!\")\n",
    "    print(f\"   📦 {total_boxes} boîtes de délimitation\")\n",
    "    print(f\"   🖼️  {len(unique_images)} images uniques\")\n",
    "    \n",
    "    return total_boxes, len(unique_images)\n",
    "\n",
    "# Vérification de l'existence des fichiers et dossiers\n",
    "print(\"🔍 Vérification des fichiers requis...\")\n",
    "\n",
    "# Vérifier les fichiers CSV d'annotations\n",
    "if not os.path.exists(TRAIN_ANN):\n",
    "    print(f\"❌ Fichier d'annotations d'entraînement introuvable: {TRAIN_ANN}\")\n",
    "    print(\"📁 Contenu du répertoire parent:\")\n",
    "    parent_dir = os.path.dirname(TRAIN_ANN)\n",
    "    if os.path.exists(parent_dir):\n",
    "        csv_files = []\n",
    "        for item in os.listdir(parent_dir):\n",
    "            print(f\"   - {item}\")\n",
    "            if item.endswith('.csv'):\n",
    "                csv_files.append(item)\n",
    "        \n",
    "        # Proposer des alternatives si des fichiers CSV existent\n",
    "        if csv_files:\n",
    "            print(f\"\\n💡 Fichiers CSV trouvés dans {parent_dir}:\")\n",
    "            for csv_file in csv_files:\n",
    "                print(f\"   - {csv_file}\")\n",
    "            \n",
    "            # Essayer de trouver un fichier d'annotations alternatif\n",
    "            possible_names = ['annotations.csv', 'train_annotations.csv', csv_files[0]]\n",
    "            for alt_name in possible_names:\n",
    "                alt_path = os.path.join(parent_dir, alt_name)\n",
    "                if os.path.exists(alt_path):\n",
    "                    print(f\"🔄 Utilisation du fichier alternatif: {alt_path}\")\n",
    "                    TRAIN_ANN = alt_path\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"⚠️  Aucun fichier d'annotations standard trouvé. Veuillez vérifier le nom du fichier.\")\n",
    "                print(f\"   Attendu: {TRAIN_ANN}\")\n",
    "                raise FileNotFoundError(f\"Fichier d'annotations d'entraînement introuvable: {TRAIN_ANN}\")\n",
    "        else:\n",
    "            print(\"   Aucun fichier CSV trouvé dans ce répertoire.\")\n",
    "            raise FileNotFoundError(f\"Fichier d'annotations d'entraînement introuvable: {TRAIN_ANN}\")\n",
    "    else:\n",
    "        print(f\"   Le répertoire {parent_dir} n'existe pas\")\n",
    "        raise FileNotFoundError(f\"Fichier d'annotations d'entraînement introuvable: {TRAIN_ANN}\")\n",
    "\n",
    "if not os.path.exists(VAL_ANN):\n",
    "    print(f\"❌ Fichier d'annotations de validation introuvable: {VAL_ANN}\")\n",
    "    print(\"📁 Contenu du répertoire parent:\")\n",
    "    parent_dir = os.path.dirname(VAL_ANN)\n",
    "    if os.path.exists(parent_dir):\n",
    "        for item in os.listdir(parent_dir):\n",
    "            print(f\"   - {item}\")\n",
    "    else:\n",
    "        print(f\"   Le répertoire {parent_dir} n'existe pas\")\n",
    "    raise FileNotFoundError(f\"Fichier d'annotations de validation introuvable: {VAL_ANN}\")\n",
    "\n",
    "# Vérifier les répertoires d'images\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(f\"❌ Répertoire d'images d'entraînement introuvable: {TRAIN_DIR}\")\n",
    "    raise FileNotFoundError(f\"Répertoire d'images d'entraînement introuvable: {TRAIN_DIR}\")\n",
    "\n",
    "if not os.path.exists(VAL_DIR):\n",
    "    print(f\"❌ Répertoire d'images de validation introuvable: {VAL_DIR}\")\n",
    "    raise FileNotFoundError(f\"Répertoire d'images de validation introuvable: {VAL_DIR}\")\n",
    "\n",
    "# Créer le répertoire de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(TFRECORD_TRAIN), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(TFRECORD_VAL), exist_ok=True)\n",
    "\n",
    "print(\"✅ Tous les fichiers requis existent\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🚀 CONVERSION INTELLIGENTE - ÉVITE LA DUPLICATION (CORRIGÉE)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "# Vérifier si les TFRecords existent déjà et s'ils sont valides\n",
    "# CORRECTION: Seuil plus bas pour éviter le bug avec les gros fichiers\n",
    "tfrecord_train_exists = os.path.exists(TFRECORD_TRAIN) and os.path.getsize(TFRECORD_TRAIN) > 1024  # > 1KB au lieu de 1MB\n",
    "tfrecord_val_exists = os.path.exists(TFRECORD_VAL) and os.path.getsize(TFRECORD_VAL) > 1024  # > 1KB au lieu de 1MB\n",
    "\n",
    "print(f\"\\n🔍 État des fichiers TFRecord (CORRIGÉ):\")\n",
    "if tfrecord_train_exists:\n",
    "    size_mb = os.path.getsize(TFRECORD_TRAIN) / (1024*1024)\n",
    "    print(f\"   ✅ TFRecord train existe: {TFRECORD_TRAIN} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    if os.path.exists(TFRECORD_TRAIN):\n",
    "        size_mb = os.path.getsize(TFRECORD_TRAIN) / (1024*1024)\n",
    "        print(f\"   ⚠️  TFRecord train trop petit: {TFRECORD_TRAIN} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ TFRecord train manquant: {TFRECORD_TRAIN}\")\n",
    "\n",
    "if tfrecord_val_exists:\n",
    "    size_mb = os.path.getsize(TFRECORD_VAL) / (1024*1024)\n",
    "    print(f\"   ✅ TFRecord validation existe: {TFRECORD_VAL} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    if os.path.exists(TFRECORD_VAL):\n",
    "        size_mb = os.path.getsize(TFRECORD_VAL) / (1024*1024)\n",
    "        print(f\"   ⚠️  TFRecord validation trop petit: {TFRECORD_VAL} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ TFRecord validation manquant: {TFRECORD_VAL}\")\n",
    "\n",
    "# Conversion train seulement si nécessaire\n",
    "if not tfrecord_train_exists:\n",
    "    print(\"\\n🚀 Conversion du dataset d'entraînement...\")\n",
    "    train_boxes, train_images = convert_csv_to_tfrecord(TRAIN_ANN, TRAIN_DIR, TFRECORD_TRAIN)\n",
    "else:\n",
    "    print(\"\\n⏭️  TFRecord d'entraînement déjà existant - Conversion ignorée\")\n",
    "    # Calculer les statistiques à partir du CSV pour l'affichage\n",
    "    df_train = pd.read_csv(TRAIN_ANN)\n",
    "    train_boxes = len(df_train)\n",
    "    train_images = df_train['filename'].nunique()\n",
    "\n",
    "# Conversion validation seulement si nécessaire\n",
    "if not tfrecord_val_exists:\n",
    "    print(\"\\n🚀 Conversion du dataset de validation...\")\n",
    "    val_boxes, val_images = convert_csv_to_tfrecord(VAL_ANN, VAL_DIR, TFRECORD_VAL)\n",
    "else:\n",
    "    print(\"\\n⏭️  TFRecord de validation déjà existant - Conversion ignorée\")\n",
    "    # Calculer les statistiques à partir du CSV pour l'affichage\n",
    "    df_val = pd.read_csv(VAL_ANN)\n",
    "    val_boxes = len(df_val)\n",
    "    val_images = df_val['filename'].nunique()\n",
    "\n",
    "print(f\"\\n📈 Résumé final:\")\n",
    "print(f\"   Train: {train_boxes} boîtes, {train_images} images\")\n",
    "print(f\"   Valid: {val_boxes} boîtes, {val_images} images\")\n",
    "print(f\"   Total: {train_boxes + val_boxes} boîtes, {train_images + val_images} images\")\n",
    "\n",
    "# Message informatif\n",
    "if tfrecord_train_exists and tfrecord_val_exists:\n",
    "    print(f\"\\n💡 Optimisation: Aucune conversion nécessaire - Fichiers déjà prêts!\")\n",
    "    print(f\"   ⚡ Temps économisé: ~2-3 minutes de conversion évitées\")\n",
    "    print(f\"   🎯 BUG DE TAILLE CORRIGÉ - Les gros fichiers sont maintenant acceptés!\")\n",
    "elif tfrecord_train_exists or tfrecord_val_exists:\n",
    "    print(f\"\\n💡 Optimisation partielle: Seuls les fichiers manquants ont été créés\")\n",
    "else:\n",
    "    print(f\"\\n🔥 Conversion complète terminée - Fichiers prêts pour l'entraînement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94aedcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration pipeline CORRIGÉE avec box_predictor: ../models/dl_model/outputs/ssd_mnv2_320/pipeline.config\n",
      "🔧 Paramètres:\n",
      "   Feature extractor: ssd_mobilenet_v2_keras (COMPATIBLE TF 2.15)\n",
      "   Box predictor: convolutional_box_predictor (AJOUTÉ)\n",
      "   Checkpoint: ../models/dl_model/outputs/ssd_mnv2_320/pretrained_checkpoint/checkpoint/ckpt-0\n",
      "   Batch size: 16\n",
      "   Steps: 30,000\n",
      "   Learning rate: 0.02 (cosine decay)\n",
      "   Warmup steps: 1500\n",
      "   Image size: 320x320\n",
      "   Classes: 2 (Healthy, Contaminated)\n",
      "   🎯 ERREUR BOX_PREDICTOR CORRIGÉE - RELANCEZ L'ENTRAÎNEMENT !\n"
     ]
    }
   ],
   "source": [
    "# Génération du fichier pipeline.config CORRECT AVEC BOX_PREDICTOR\n",
    "pipeline_config_content = f\"\"\"# Pipeline config pour SSD MobileNet V2 Keras (TF 2.15 compatible)\n",
    "\n",
    "model {{\n",
    "  ssd {{\n",
    "    inplace_batchnorm_update: true\n",
    "    freeze_batchnorm: false\n",
    "    num_classes: 2\n",
    "    image_resizer {{\n",
    "      fixed_shape_resizer {{\n",
    "        height: {IMG_SIZE}\n",
    "        width: {IMG_SIZE}\n",
    "      }}\n",
    "    }}\n",
    "    feature_extractor {{\n",
    "      type: 'ssd_mobilenet_v2_keras'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1\n",
    "      conv_hyperparams {{\n",
    "        activation: RELU_6,\n",
    "        regularizer {{\n",
    "          l2_regularizer {{\n",
    "            weight: 0.00004\n",
    "          }}\n",
    "        }}\n",
    "        initializer {{\n",
    "          truncated_normal_initializer {{\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }}\n",
    "        }}\n",
    "        batch_norm {{\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }}\n",
    "      }}\n",
    "      use_depthwise: true\n",
    "    }}\n",
    "    box_predictor {{\n",
    "      convolutional_box_predictor {{\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        class_prediction_bias_init: -4.6\n",
    "        conv_hyperparams {{\n",
    "          activation: RELU_6,\n",
    "          regularizer {{\n",
    "            l2_regularizer {{\n",
    "              weight: 0.00004\n",
    "            }}\n",
    "          }}\n",
    "          initializer {{\n",
    "            random_normal_initializer {{\n",
    "              stddev: 0.01\n",
    "              mean: 0.0\n",
    "            }}\n",
    "          }}\n",
    "          batch_norm {{\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    box_coder {{\n",
    "      faster_rcnn_box_coder {{\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }}\n",
    "    }}\n",
    "    matcher {{\n",
    "      argmax_matcher {{\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "        use_matmul_gather: true\n",
    "      }}\n",
    "    }}\n",
    "    similarity_calculator {{\n",
    "      iou_similarity {{\n",
    "      }}\n",
    "    }}\n",
    "    encode_background_as_zeros: true\n",
    "    anchor_generator {{\n",
    "      ssd_anchor_generator {{\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }}\n",
    "    }}\n",
    "    post_processing {{\n",
    "      batch_non_max_suppression {{\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }}\n",
    "      score_converter: SIGMOID\n",
    "    }}\n",
    "    normalize_loss_by_num_matches: true\n",
    "    loss {{\n",
    "      classification_loss {{\n",
    "        weighted_sigmoid_focal {{\n",
    "          alpha: 0.25\n",
    "          gamma: 1.5\n",
    "        }}\n",
    "      }}\n",
    "      localization_loss {{\n",
    "        weighted_smooth_l1 {{\n",
    "          delta: 1.0\n",
    "        }}\n",
    "      }}\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "train_config: {{\n",
    "  fine_tune_checkpoint_version: V2\n",
    "  fine_tune_checkpoint: \"{CHECKPOINT_PATH}\"\n",
    "  fine_tune_checkpoint_type: \"detection\"\n",
    "  batch_size: {BATCH_SIZE}\n",
    "  sync_replicas: true\n",
    "  startup_delay_steps: 0\n",
    "  replicas_to_aggregate: 8\n",
    "  num_steps: {NUM_STEPS}\n",
    "  optimizer {{\n",
    "    momentum_optimizer: {{\n",
    "      learning_rate: {{\n",
    "        cosine_decay_learning_rate {{\n",
    "          learning_rate_base: {BASE_LR}\n",
    "          total_steps: {NUM_STEPS}\n",
    "          warmup_learning_rate: 0.0\n",
    "          warmup_steps: {WARMUP_STEPS}\n",
    "        }}\n",
    "      }}\n",
    "      momentum_optimizer_value: 0.9\n",
    "    }}\n",
    "    use_moving_average: false\n",
    "  }}\n",
    "  max_number_of_boxes: 100\n",
    "  unpad_groundtruth_tensors: false\n",
    "}}\n",
    "\n",
    "train_input_reader: {{\n",
    "  label_map_path: \"{LABEL_MAP}\"\n",
    "  tf_record_input_reader {{\n",
    "    input_path: \"{TFRECORD_TRAIN}\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "eval_config: {{\n",
    "  metrics_set: \"coco_detection_metrics\"\n",
    "  num_examples: {val_images}\n",
    "}}\n",
    "\n",
    "eval_input_reader: {{\n",
    "  label_map_path: \"{LABEL_MAP}\"\n",
    "  shuffle: false\n",
    "  num_epochs: 1\n",
    "  tf_record_input_reader {{\n",
    "    input_path: \"{TFRECORD_VAL}\"\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Sauvegarde du fichier de configuration CORRECT\n",
    "PIPELINE_CFG = f\"{OUTPUT_DIR}/pipeline.config\"\n",
    "with open(PIPELINE_CFG, 'w') as f:\n",
    "    f.write(pipeline_config_content)\n",
    "\n",
    "print(f\"✅ Configuration pipeline CORRIGÉE avec box_predictor: {PIPELINE_CFG}\")\n",
    "print(f\"🔧 Paramètres:\")\n",
    "print(f\"   Feature extractor: ssd_mobilenet_v2_keras (COMPATIBLE TF 2.15)\")\n",
    "print(f\"   Box predictor: convolutional_box_predictor (AJOUTÉ)\")\n",
    "print(f\"   Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Steps: {NUM_STEPS:,}\")\n",
    "print(f\"   Learning rate: {BASE_LR} (cosine decay)\")\n",
    "print(f\"   Warmup steps: {WARMUP_STEPS}\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Classes: 2 (Healthy, Contaminated)\")\n",
    "print(f\"   🎯 ERREUR BOX_PREDICTOR CORRIGÉE - RELANCEZ L'ENTRAÎNEMENT !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892d00a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Commande pour lancer l'entraînement:\n",
      "============================================================\n",
      "python model_main_tf2.py \\\n",
      "  --pipeline_config_path=../models/dl_model/outputs/ssd_mnv2_320/pipeline.config \\\n",
      "  --model_dir=../models/dl_model/outputs/ssd_mnv2_320 \\\n",
      "  --alsologtostderr\n",
      "============================================================\n",
      "📁 Répertoire de travail: /home/sarsator/projets/gaia_vision/training/notebook\n",
      "📄 Config pipeline: ../models/dl_model/outputs/ssd_mnv2_320/pipeline.config\n",
      "📂 Répertoire de sortie: ../models/dl_model/outputs/ssd_mnv2_320\n",
      "\\n💡 Pour surveiller l'entraînement en temps réel:\n",
      "   tensorboard --logdir=../models/dl_model/outputs/ssd_mnv2_320 --port=6006\n"
     ]
    }
   ],
   "source": [
    "# Commande d'entraînement\n",
    "# Note: Cette cellule affiche la commande à exécuter dans un terminal\n",
    "# Pour lancer l'entraînement depuis le notebook, décommentez et exécutez la section suivante\n",
    "\n",
    "print(\"🚀 Commande pour lancer l'entraînement:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "training_command = f\"\"\"python model_main_tf2.py \\\\\n",
    "  --pipeline_config_path={PIPELINE_CFG} \\\\\n",
    "  --model_dir={OUTPUT_DIR} \\\\\n",
    "  --alsologtostderr\"\"\"\n",
    "\n",
    "print(training_command)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"📁 Répertoire de travail: {os.getcwd()}\")\n",
    "print(f\"📄 Config pipeline: {PIPELINE_CFG}\")\n",
    "print(f\"📂 Répertoire de sortie: {OUTPUT_DIR}\")\n",
    "\n",
    "# Lancement direct depuis le notebook (décommentez si souhaité)\n",
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# print(\"\\\\n🏃 Lancement de l'entraînement...\")\n",
    "# try:\n",
    "#     result = subprocess.run([\n",
    "#         sys.executable, \"model_main_tf2.py\",\n",
    "#         f\"--pipeline_config_path={PIPELINE_CFG}\",\n",
    "#         f\"--model_dir={OUTPUT_DIR}\",\n",
    "#         \"--alsologtostderr\"\n",
    "#     ], capture_output=True, text=True, cwd=\".\")\n",
    "#     \n",
    "#     print(\"STDOUT:\", result.stdout)\n",
    "#     if result.stderr:\n",
    "#         print(\"STDERR:\", result.stderr)\n",
    "#     print(f\"Code de retour: {result.returncode}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Erreur lors du lancement: {e}\")\n",
    "\n",
    "print(\"\\\\n💡 Pour surveiller l'entraînement en temps réel:\")\n",
    "print(f\"   tensorboard --logdir={OUTPUT_DIR} --port=6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29225d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Diagnostic complet du système...\n",
      "============================================================\n",
      "📋 1. Vérification des fichiers requis:\n",
      "   ✅ Label map: ../models/dl_model/outputs/ssd_mnv2_320/label_map.pbtxt (0.0 MB)\n",
      "   ✅ TFRecord train: ../models/dl_model/outputs/ssd_mnv2_320/train.record (4669.5 MB)\n",
      "   ✅ TFRecord validation: ../models/dl_model/outputs/ssd_mnv2_320/val.record (302.0 MB)\n",
      "   ✅ Pipeline config: ../models/dl_model/outputs/ssd_mnv2_320/pipeline.config (0.0 MB)\n",
      "   ✅ Checkpoint: ../models/dl_model/outputs/ssd_mnv2_320/pretrained_checkpoint/checkpoint/ckpt-0.index (0.0 MB)\n",
      "\n",
      "📁 2. Structure du répertoire de sortie (../models/dl_model/outputs/ssd_mnv2_320):\n",
      "   📄 label_map.pbtxt (0.0 MB)\n",
      "   📄 pipeline.config (0.0 MB)\n",
      "   📁 pretrained_checkpoint/\n",
      "   📄 train.record (4669.5 MB)\n",
      "   📄 val.record (302.0 MB)\n",
      "\n",
      "📊 3. Vérification des données:\n",
      "   ✅ Dataset train: 9186 images, 16787 boîtes\n",
      "   ✅ Dataset validation: 743 images, 1006 boîtes\n",
      "   📈 Ratio: Train 92.5% / Val 7.5%\n",
      "\n",
      "🎮 4. Configuration GPU:\n",
      "   🎮 GPUs détectés: 1\n",
      "   ✅ GPU 0: /physical_device:GPU:0\n",
      "\n",
      "🧪 5. Test de l'API TensorFlow Object Detection:\n",
      "   ✅ config_util importé avec succès\n",
      "   ✅ model_builder importé avec succès\n",
      "   ✅ TensorFlow Object Detection API accessible\n",
      "   ✅ Pipeline config valide\n",
      "\n",
      "💾 6. Estimation des ressources:\n",
      "   🎯 Mémoire GPU estimée: ~0.0 GB par batch\n",
      "   ⏱️  Steps par epoch estimé: ~574\n",
      "   🕐 Durée estimée totale: 2-3h (GPU)\n",
      "\n",
      "============================================================\n",
      "🎉 DIAGNOSTIC RÉUSSI - Prêt pour l'entraînement!\n",
      "▶️  Vous pouvez maintenant exécuter la cellule d'entraînement\n",
      "============================================================\n",
      "\n",
      "💡 Note sur TensorBoard:\n",
      "   📊 TensorBoard est vide car l'entraînement n'a pas encore commencé\n",
      "   ⏳ Les métriques apparaîtront dès le premier step d'entraînement\n",
      "   🔄 Rafraîchissez TensorBoard après avoir lancé l'entraînement\n",
      "   ✅ model_builder importé avec succès\n",
      "   ✅ TensorFlow Object Detection API accessible\n",
      "   ✅ Pipeline config valide\n",
      "\n",
      "💾 6. Estimation des ressources:\n",
      "   🎯 Mémoire GPU estimée: ~0.0 GB par batch\n",
      "   ⏱️  Steps par epoch estimé: ~574\n",
      "   🕐 Durée estimée totale: 2-3h (GPU)\n",
      "\n",
      "============================================================\n",
      "🎉 DIAGNOSTIC RÉUSSI - Prêt pour l'entraînement!\n",
      "▶️  Vous pouvez maintenant exécuter la cellule d'entraînement\n",
      "============================================================\n",
      "\n",
      "💡 Note sur TensorBoard:\n",
      "   📊 TensorBoard est vide car l'entraînement n'a pas encore commencé\n",
      "   ⏳ Les métriques apparaîtront dès le premier step d'entraînement\n",
      "   🔄 Rafraîchissez TensorBoard après avoir lancé l'entraînement\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🔍 DIAGNOSTIC ET VÉRIFICATION AVANT ENTRAÎNEMENT\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🔍 Diagnostic complet du système...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Vérification des fichiers requis\n",
    "print(\"📋 1. Vérification des fichiers requis:\")\n",
    "files_to_check = [\n",
    "    (\"Label map\", LABEL_MAP),\n",
    "    (\"TFRecord train\", TFRECORD_TRAIN), \n",
    "    (\"TFRecord validation\", TFRECORD_VAL),\n",
    "    (\"Pipeline config\", PIPELINE_CFG),\n",
    "    (\"Checkpoint\", CHECKPOINT_PATH + \".index\")  # Vérifie le fichier .index du checkpoint\n",
    "]\n",
    "\n",
    "all_files_exist = True\n",
    "for name, path in files_to_check:\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path) / (1024*1024)  # Size in MB\n",
    "        print(f\"   ✅ {name}: {path} ({size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ {name}: {path} (MANQUANT)\")\n",
    "        all_files_exist = False\n",
    "\n",
    "# 2. Vérification du répertoire de sortie\n",
    "print(f\"\\n📁 2. Structure du répertoire de sortie ({OUTPUT_DIR}):\")\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    for item in os.listdir(OUTPUT_DIR):\n",
    "        item_path = os.path.join(OUTPUT_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   📁 {item}/\")\n",
    "        else:\n",
    "            size = os.path.getsize(item_path) / (1024*1024)\n",
    "            print(f\"   📄 {item} ({size:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"   ❌ Le répertoire {OUTPUT_DIR} n'existe pas\")\n",
    "    all_files_exist = False\n",
    "\n",
    "# 3. Vérification des données d'entraînement\n",
    "print(f\"\\n📊 3. Vérification des données:\")\n",
    "if 'train_boxes' in locals() and 'val_boxes' in locals():\n",
    "    print(f\"   ✅ Dataset train: {train_images} images, {train_boxes} boîtes\")\n",
    "    print(f\"   ✅ Dataset validation: {val_images} images, {val_boxes} boîtes\")\n",
    "    \n",
    "    # Ratio de données\n",
    "    total_images = train_images + val_images\n",
    "    train_ratio = train_images / total_images * 100\n",
    "    val_ratio = val_images / total_images * 100\n",
    "    print(f\"   📈 Ratio: Train {train_ratio:.1f}% / Val {val_ratio:.1f}%\")\n",
    "else:\n",
    "    print(\"   ⚠️  Variables de données non définies - Exécutez d'abord la conversion CSV→TFRecord\")\n",
    "    all_files_exist = False\n",
    "\n",
    "# 4. Vérification GPU\n",
    "print(f\"\\n🎮 4. Configuration GPU:\")\n",
    "if 'gpus' in locals():\n",
    "    print(f\"   🎮 GPUs détectés: {len(gpus)}\")\n",
    "    if gpus:\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   ✅ GPU {i}: {gpu.name}\")\n",
    "    else:\n",
    "        print(\"   ⚠️  Aucun GPU détecté - Entraînement sera très lent\")\n",
    "else:\n",
    "    print(\"   ❌ Configuration GPU non initialisée\")\n",
    "\n",
    "# 5. Test du modèle TF Object Detection API\n",
    "print(f\"\\n🧪 5. Test de l'API TensorFlow Object Detection:\")\n",
    "try:\n",
    "    # Vérifier si l'API TF Object Detection est accessible\n",
    "    import sys\n",
    "    \n",
    "    # Utiliser le chemin local du modèle cloné\n",
    "    research_path = './tensorflow_models/research'\n",
    "    slim_path = './tensorflow_models/research/slim'\n",
    "    \n",
    "    if research_path not in sys.path:\n",
    "        sys.path.insert(0, research_path)\n",
    "    if slim_path not in sys.path:\n",
    "        sys.path.insert(0, slim_path)\n",
    "    \n",
    "    # Vérifier que le répertoire existe\n",
    "    if not os.path.exists(research_path):\n",
    "        raise ImportError(f\"Répertoire {research_path} non trouvé\")\n",
    "    \n",
    "    # Test d'import avec gestion des erreurs de compatibilité\n",
    "    from object_detection.utils import config_util\n",
    "    print(\"   ✅ config_util importé avec succès\")\n",
    "    \n",
    "    # Test optionnel du model_builder (peut échouer avec certaines versions)\n",
    "    try:\n",
    "        from object_detection.builders import model_builder\n",
    "        print(\"   ✅ model_builder importé avec succès\")\n",
    "    except (ImportError, AttributeError) as e:\n",
    "        print(f\"   ⚠️  model_builder non disponible: {e}\")\n",
    "        print(\"   💡 Ceci peut être dû à des incompatibilités de versions mais n'empêche pas l'entraînement\")\n",
    "    \n",
    "    print(\"   ✅ TensorFlow Object Detection API accessible\")\n",
    "    \n",
    "    # Test de lecture de la config\n",
    "    if os.path.exists(PIPELINE_CFG):\n",
    "        try:\n",
    "            configs = config_util.get_configs_from_pipeline_file(PIPELINE_CFG)\n",
    "            print(\"   ✅ Pipeline config valide\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Erreur pipeline config: {e}\")\n",
    "            all_files_exist = False\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"   ❌ TensorFlow Object Detection API non trouvée: {e}\")\n",
    "    print(\"   💡 Installation requise:\")\n",
    "    print(\"      git clone https://github.com/tensorflow/models.git tensorflow_models\")\n",
    "    print(\"      cd tensorflow_models/research\")\n",
    "    print(\"      protoc object_detection/protos/*.proto --python_out=.\")\n",
    "    print(\"      cp object_detection/packages/tf2/setup.py .\")\n",
    "    print(\"      pip install .\")\n",
    "    all_files_exist = False\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️  Erreur de compatibilité: {e}\")\n",
    "    print(\"   💡 L'API peut fonctionner malgré cette erreur\")\n",
    "    print(\"   🔧 Essayez: pip install --upgrade tensorflow tensorflow-object-detection-api\")\n",
    "\n",
    "# 6. Estimation des ressources\n",
    "print(f\"\\n💾 6. Estimation des ressources:\")\n",
    "estimated_model_size = BATCH_SIZE * IMG_SIZE * IMG_SIZE * 3 * 4 / (1024**3)  # GB\n",
    "print(f\"   🎯 Mémoire GPU estimée: ~{estimated_model_size:.1f} GB par batch\")\n",
    "print(f\"   ⏱️  Steps par epoch estimé: ~{train_images // BATCH_SIZE}\")\n",
    "print(f\"   🕐 Durée estimée totale: {'2-3h (GPU)' if gpus else '20-30h (CPU)'}\")\n",
    "\n",
    "# Résumé final\n",
    "print(f\"\\n{'='*60}\")\n",
    "if all_files_exist:\n",
    "    print(\"🎉 DIAGNOSTIC RÉUSSI - Prêt pour l'entraînement!\")\n",
    "    print(\"▶️  Vous pouvez maintenant exécuter la cellule d'entraînement\")\n",
    "else:\n",
    "    print(\"❌ DIAGNOSTIC ÉCHOUÉ - Problèmes détectés\")\n",
    "    print(\"🔧 Corrigez les erreurs ci-dessus avant de continuer\")\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Note importante sur TensorBoard\n",
    "if all_files_exist:\n",
    "    print(f\"\\n💡 Note sur TensorBoard:\")\n",
    "    print(f\"   📊 TensorBoard est vide car l'entraînement n'a pas encore commencé\")\n",
    "    print(f\"   ⏳ Les métriques apparaîtront dès le premier step d'entraînement\")\n",
    "    print(f\"   🔄 Rafraîchissez TensorBoard après avoir lancé l'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de5bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Démarrage de TensorBoard...\n",
      "   🧹 Instances précédentes arrêtées\n",
      "🚀 Lancement de TensorBoard...\n",
      "   Commande: /home/sarsator/projets/gaia_vision/.venv/bin/python -m tensorboard.main --logdir=../models/dl_model/outputs/ssd_mnv2_320 --port=6006 --host=0.0.0.0\n",
      "   🧹 Instances précédentes arrêtées\n",
      "🚀 Lancement de TensorBoard...\n",
      "   Commande: /home/sarsator/projets/gaia_vision/.venv/bin/python -m tensorboard.main --logdir=../models/dl_model/outputs/ssd_mnv2_320 --port=6006 --host=0.0.0.0\n",
      "✅ TensorBoard démarré avec succès!\n",
      "📊 Accès: http://localhost:6006\n",
      "✅ TensorBoard démarré avec succès!\n",
      "📊 Accès: http://localhost:6006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:6006\" target=\"_blank\">🔗 Ouvrir TensorBoard dans un nouvel onglet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💡 Pour arrêter TensorBoard plus tard:\n",
      "   pkill -f tensorboard\n",
      "\n",
      "📈 Métriques à surveiller:\n",
      "   • Loss/total_loss (doit diminuer)\n",
      "   • Loss/classification_loss\n",
      "   • Loss/localization_loss\n",
      "   • learning_rate\n",
      "   • DetectionBoxes_Precision/mAP (après évaluation)\n",
      "   • DetectionBoxes_Recall/AR@100 (après évaluation)\n",
      "\n",
      "ℹ️  Note: Les métriques apparaîtront une fois l'entraînement commencé\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 📊 LANCEMENT TENSORBOARD\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"📊 Démarrage de TensorBoard...\")\n",
    "\n",
    "# Arrêter toute instance existante\n",
    "try:\n",
    "    subprocess.run([\"pkill\", \"-f\", \"tensorboard\"], capture_output=True)\n",
    "    time.sleep(1)\n",
    "    print(\"   🧹 Instances précédentes arrêtées\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Chemin Python correct pour l'environnement virtuel\n",
    "python_path = \"/home/sarsator/projets/gaia_vision/.venv/bin/python\"\n",
    "\n",
    "# Lancer TensorBoard avec le bon interpréteur\n",
    "tensorboard_cmd = f\"{python_path} -m tensorboard.main --logdir={OUTPUT_DIR} --port=6006 --host=0.0.0.0\"\n",
    "\n",
    "print(f\"🚀 Lancement de TensorBoard...\")\n",
    "print(f\"   Commande: {tensorboard_cmd}\")\n",
    "\n",
    "# Utiliser nohup pour lancer en arrière-plan sans bloquer\n",
    "launch_cmd = f\"nohup {tensorboard_cmd} > tensorboard.log 2>&1 &\"\n",
    "os.system(launch_cmd)\n",
    "\n",
    "time.sleep(3)  # Attendre que TensorBoard démarre\n",
    "\n",
    "# Vérifier si TensorBoard fonctionne\n",
    "try:\n",
    "    result = subprocess.run([\"curl\", \"-s\", \"http://localhost:6006\"], \n",
    "                           capture_output=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ TensorBoard démarré avec succès!\")\n",
    "        print(\"📊 Accès: http://localhost:6006\")\n",
    "        \n",
    "        # Afficher le lien cliquable dans Jupyter\n",
    "        from IPython.display import HTML, display\n",
    "        display(HTML('<a href=\"http://localhost:6006\" target=\"_blank\">🔗 Ouvrir TensorBoard dans un nouvel onglet</a>'))\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️  TensorBoard en cours de démarrage...\")\n",
    "        print(\"📊 Essayez: http://localhost:6006 dans quelques secondes\")\n",
    "except:\n",
    "    print(\"⚠️  TensorBoard en cours de démarrage...\")\n",
    "    print(\"📊 Essayez: http://localhost:6006 dans quelques secondes\")\n",
    "\n",
    "print()\n",
    "print(\"💡 Pour arrêter TensorBoard plus tard:\")\n",
    "print(\"   pkill -f tensorboard\")\n",
    "print()\n",
    "print(\"📈 Métriques à surveiller:\")\n",
    "print(\"   • Loss/total_loss (doit diminuer)\")\n",
    "print(\"   • Loss/classification_loss\") \n",
    "print(\"   • Loss/localization_loss\")\n",
    "print(\"   • learning_rate\")\n",
    "print(\"   • DetectionBoxes_Precision/mAP (après évaluation)\")\n",
    "print(\"   • DetectionBoxes_Recall/AR@100 (après évaluation)\")\n",
    "print()\n",
    "print(\"ℹ️  Note: Les métriques apparaîtront une fois l'entraînement commencé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23ab67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Instructions pour l'entraînement\n",
      "============================================================\n",
      "✅ Système prêt pour l'entraînement!\n",
      "\n",
      "📋 Méthodes d'entraînement disponibles:\n",
      "\n",
      "1️⃣  MÉTHODE RECOMMANDÉE - Script Bash:\n",
      "   • Plus stable et fiable\n",
      "   • Ouvrez un terminal dans ce répertoire\n",
      "   • Exécutez: ./train_ssd_mobilenet.sh\n",
      "\n",
      "2️⃣  Alternative - Commande directe:\n",
      "   • Dans un terminal, exécutez:\n",
      "   export PYTHONPATH=/home/sarsator/projets/gaia_vision/training/notebook/tensorflow_models/research:/home/sarsator/projets/gaia_vision/training/notebook/tensorflow_models/research/slim:$PYTHONPATH\n",
      "   python tensorflow_models/research/object_detection/model_main_tf2.py \\\n",
      "     --model_dir=../models/dl_model/outputs/ssd_mnv2_320 \\\n",
      "     --pipeline_config_path=../models/dl_model/outputs/ssd_mnv2_320/pipeline.config \\\n",
      "     --num_train_steps=30000 \\\n",
      "     --alsologtostderr\n",
      "\n",
      "⏱️  Durée estimée:\n",
      "   🎮 Avec GPU RTX 4080: ~2-3h pour 30,000 steps\n",
      "\n",
      "📊 Surveillance:\n",
      "   • TensorBoard: http://localhost:6006\n",
      "   • Logs en temps réel dans le terminal\n",
      "   • Checkpoints sauvés dans: ../models/dl_model/outputs/ssd_mnv2_320\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🚀 INSTRUCTIONS D'ENTRAÎNEMENT\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🚀 Instructions pour l'entraînement\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'all_files_exist' in locals() and all_files_exist:\n",
    "    print(\"✅ Système prêt pour l'entraînement!\")\n",
    "    print()\n",
    "    print(\"📋 Méthodes d'entraînement disponibles:\")\n",
    "    print()\n",
    "    print(\"1️⃣  MÉTHODE RECOMMANDÉE - Script Bash:\")\n",
    "    print(\"   • Plus stable et fiable\")\n",
    "    print(\"   • Ouvrez un terminal dans ce répertoire\")\n",
    "    print(\"   • Exécutez: ./train_ssd_mobilenet.sh\")\n",
    "    print()\n",
    "    print(\"2️⃣  Alternative - Commande directe:\")\n",
    "    print(\"   • Dans un terminal, exécutez:\")\n",
    "    \n",
    "    # Vérifier si tensorflow_models existe\n",
    "    api_dir = \"tensorflow_models\"\n",
    "    model_main_path = f\"{api_dir}/research/object_detection/model_main_tf2.py\"\n",
    "    \n",
    "    if os.path.exists(model_main_path):\n",
    "        research_path = os.path.abspath(f\"{api_dir}/research\")\n",
    "        slim_path = os.path.abspath(f\"{api_dir}/research/slim\")\n",
    "        \n",
    "        print(f\"   export PYTHONPATH={research_path}:{slim_path}:$PYTHONPATH\")\n",
    "        print(f\"   python {model_main_path} \\\\\")\n",
    "        print(f\"     --model_dir={OUTPUT_DIR} \\\\\")\n",
    "        print(f\"     --pipeline_config_path={PIPELINE_CFG} \\\\\")\n",
    "        print(f\"     --num_train_steps={NUM_STEPS} \\\\\")\n",
    "        print(f\"     --alsologtostderr\")\n",
    "    else:\n",
    "        print(\"   ❌ TensorFlow Object Detection API non installée\")\n",
    "        print(\"   💡 Installez d'abord:\")\n",
    "        print(\"      git clone https://github.com/tensorflow/models.git tensorflow_models\")\n",
    "        print(\"      cd tensorflow_models/research\")\n",
    "        print(\"      protoc object_detection/protos/*.proto --python_out=.\")\n",
    "    \n",
    "    print()\n",
    "    print(\"⏱️  Durée estimée:\")\n",
    "    if 'gpus' in locals() and gpus:\n",
    "        print(f\"   🎮 Avec GPU RTX 4080: ~2-3h pour {NUM_STEPS:,} steps\")\n",
    "    else:\n",
    "        print(f\"   🐌 Avec CPU: ~20-30h pour {NUM_STEPS:,} steps\")\n",
    "    \n",
    "    print()\n",
    "    print(\"📊 Surveillance:\")\n",
    "    print(\"   • TensorBoard: http://localhost:6006\")\n",
    "    print(\"   • Logs en temps réel dans le terminal\")\n",
    "    print(\"   • Checkpoints sauvés dans:\", OUTPUT_DIR)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Système non prêt pour l'entraînement\")\n",
    "    print(\"🔧 Exécutez d'abord toutes les cellules précédentes\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ LANCEMENT ENTRAÎNEMENT FINAL - AVEC FILTRAGE INTELLIGENT !\n",
    "print(\"🚀 Lancement de l'entraînement final...\")\n",
    "print(\"📊 TensorBoard: http://localhost:6006\")\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Vérifications rapides\n",
    "print(f\"✅ Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"✅ Config: {PIPELINE_CFG}\")\n",
    "\n",
    "# Commande d'entraînement\n",
    "cmd = [\n",
    "    sys.executable, \n",
    "    \"tensorflow_models/research/object_detection/model_main_tf2.py\",\n",
    "    f\"--model_dir={OUTPUT_DIR}\",\n",
    "    f\"--pipeline_config_path={PIPELINE_CFG}\",\n",
    "    f\"--num_train_steps={NUM_STEPS}\",\n",
    "    \"--alsologtostderr\",\n",
    "    \"--use_tpu=False\"\n",
    "]\n",
    "\n",
    "# Variables d'environnement\n",
    "env = os.environ.copy()\n",
    "research_path = os.path.abspath(\"tensorflow_models/research\")\n",
    "slim_path = os.path.abspath(\"tensorflow_models/research/slim\")\n",
    "env[\"PYTHONPATH\"] = f\"{research_path}:{slim_path}:{env.get('PYTHONPATH', '')}\"\n",
    "\n",
    "print(f\"🔥 DÉMARRAGE DE L'ENTRAÎNEMENT...\")\n",
    "\n",
    "try:\n",
    "    # Test avec timeout très court pour diagnostiquer\n",
    "    process = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    # Filtrer seulement les erreurs importantes\n",
    "    if process.stderr:\n",
    "        lines = process.stderr.split('\\n')\n",
    "        important_lines = []\n",
    "        for line in lines:\n",
    "            line_lower = line.lower()\n",
    "            if any(keyword in line_lower for keyword in ['error', 'exception', 'traceback', 'failed', 'valueerror', 'importerror', 'filenotfounderror']):\n",
    "                important_lines.append(line)\n",
    "        \n",
    "        if important_lines:\n",
    "            print(\"⚠️  ERREURS IMPORTANTES DÉTECTÉES:\")\n",
    "            for line in important_lines[:10]:  # Max 10 lignes\n",
    "                print(f\"   {line}\")\n",
    "        else:\n",
    "            print(\"✅ Aucune erreur critique détectée dans les 10 premières secondes\")\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(\"🎉 DIAGNOSTIC POSITIF - Processus se lance bien !\")\n",
    "    else:\n",
    "        print(f\"❌ Code d'erreur: {process.returncode}\")\n",
    "            \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"⏰ Timeout après 10s - C'est NORMAL !\")\n",
    "    print(\"✅ Le processus se lance correctement\")\n",
    "    print(\"🚀 Lancement de l'entraînement complet maintenant...\")\n",
    "    \n",
    "    # Maintenant lancer VRAIMENT l'entraînement sans timeout\n",
    "    try:\n",
    "        process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(f\"🎯 PID de l'entraînement: {process.pid}\")\n",
    "        print(\"\udcc8 Surveillez TensorBoard: http://localhost:6006\")\n",
    "        print(\"⏱️  L'entraînement est en cours...\")\n",
    "        \n",
    "        # Attendre un peu puis vérifier\n",
    "        import time\n",
    "        time.sleep(5)\n",
    "        \n",
    "        if process.poll() is None:\n",
    "            print(\"✅ ENTRAÎNEMENT EN COURS - Le processus fonctionne !\")\n",
    "            print(\"💡 Laissez-le tourner et surveillez TensorBoard\")\n",
    "        else:\n",
    "            stdout, stderr = process.communicate()\n",
    "            print(f\"❌ Processus terminé avec code: {process.returncode}\")\n",
    "            # Montrer seulement les dernières lignes d'erreur\n",
    "            if stderr:\n",
    "                error_lines = stderr.split('\\n')[-5:]\n",
    "                print(\"\udccb Dernières erreurs:\")\n",
    "                for line in error_lines:\n",
    "                    if line.strip():\n",
    "                        print(f\"   {line}\")\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du lancement: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur de diagnostic: {e}\")\n",
    "\n",
    "print(\"🏁 Diagnostic terminé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8dcd32",
   "metadata": {},
   "source": [
    "# 🎯 INSTRUCTIONS FINALES\n",
    "\n",
    "## ✅ SYSTÈME PRÊT !\n",
    "\n",
    "**TensorBoard** est maintenant actif sur : **http://localhost:6006**\n",
    "\n",
    "## 🚀 Pour lancer l'entraînement :\n",
    "\n",
    "1. **Exécutez la cellule précédente** (celle du lancement d'entraînement)\n",
    "2. **Attendez** que l'entraînement commence (peut prendre 1-2 minutes)\n",
    "3. **Surveillez TensorBoard** - les métriques apparaîtront automatiquement\n",
    "\n",
    "## 📊 Métriques importantes à surveiller :\n",
    "\n",
    "- **Loss/total_loss** : Doit diminuer progressivement\n",
    "- **Loss/classification_loss** : Perte de classification\n",
    "- **Loss/localization_loss** : Perte de localisation  \n",
    "- **learning_rate** : Taux d'apprentissage (décroît avec cosine schedule)\n",
    "\n",
    "## ⏱️ Durée estimée : **2-3 heures** avec RTX 4080\n",
    "\n",
    "## 💡 Notes importantes :\n",
    "\n",
    "- L'entraînement peut être interrompu avec Ctrl+C\n",
    "- Les checkpoints sont sauvés automatiquement toutes les 3000 steps\n",
    "- TensorBoard se met à jour en temps réel\n",
    "- Vous pouvez fermer le notebook, l'entraînement continuera en arrière-plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4731888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Exportation du modèle entraîné pour l'inférence...\n",
      "📦 Commande d'exportation:\n",
      "/home/sarsator/projets/gaia_vision/.venv/bin/python tensorflow_models/research/object_detection/exporter_main_v2.py --input_type=image_tensor --pipeline_config_path=../models/dl_model/outputs/ssd_mnv2_320/pipeline.config --trained_checkpoint_dir=../models/dl_model/outputs/ssd_mnv2_320 --output_directory=../models/dl_model/outputs/ssd_mnv2_320/exported_model\n",
      "📂 Répertoire de sortie: ../models/dl_model/outputs/ssd_mnv2_320/exported_model\n",
      "⏳ Exportation en cours...\n",
      "✅ EXPORTATION RÉUSSIE !\n",
      "📁 Modèle exporté dans: ../models/dl_model/outputs/ssd_mnv2_320/exported_model\n",
      "✅ Dossier saved_model créé\n",
      "   📄 fingerprint.pb\n",
      "   📄 variables\n",
      "   📄 saved_model.pb\n",
      "   📄 assets\n",
      "✅ Checkpoint d'exportation créé\n",
      "\n",
      "🎯 Le modèle est maintenant prêt pour l'inférence !\n",
      "\n",
      "📋 Résumé:\n",
      "   🤖 Modèle: SSD MobileNet V2 320x320\n",
      "   🎯 Classes: Healthy, Contaminated\n",
      "   📈 Entraînement: 30,000 steps terminés\n",
      "   💾 Modèle exporté: ../models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model\n",
      "   📊 TensorBoard: http://localhost:6006\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🎯 EXPORTATION DU MODÈLE ENTRAÎNÉ POUR INFÉRENCE\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"🚀 Exportation du modèle entraîné pour l'inférence...\")\n",
    "\n",
    "# Chemins pour l'exportation\n",
    "EXPORT_DIR = f\"{OUTPUT_DIR}/exported_model\"\n",
    "CHECKPOINT_DIR = OUTPUT_DIR\n",
    "PIPELINE_CONFIG = f\"{OUTPUT_DIR}/pipeline.config\"\n",
    "\n",
    "# Créer le répertoire d'exportation\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# Variables d'environnement\n",
    "env = os.environ.copy()\n",
    "research_path = os.path.abspath(\"tensorflow_models/research\")\n",
    "slim_path = os.path.abspath(\"tensorflow_models/research/slim\")\n",
    "env[\"PYTHONPATH\"] = f\"{research_path}:{slim_path}:{env.get('PYTHONPATH', '')}\"\n",
    "\n",
    "# Commande d'exportation\n",
    "export_cmd = [\n",
    "    sys.executable,\n",
    "    \"tensorflow_models/research/object_detection/exporter_main_v2.py\",\n",
    "    f\"--input_type=image_tensor\",\n",
    "    f\"--pipeline_config_path={PIPELINE_CONFIG}\",\n",
    "    f\"--trained_checkpoint_dir={CHECKPOINT_DIR}\",\n",
    "    f\"--output_directory={EXPORT_DIR}\"\n",
    "]\n",
    "\n",
    "print(f\"📦 Commande d'exportation:\")\n",
    "print(\" \".join(export_cmd))\n",
    "print(f\"📂 Répertoire de sortie: {EXPORT_DIR}\")\n",
    "\n",
    "try:\n",
    "    print(\"⏳ Exportation en cours...\")\n",
    "    result = subprocess.run(export_cmd, env=env, capture_output=True, text=True, timeout=300)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ EXPORTATION RÉUSSIE !\")\n",
    "        print(f\"📁 Modèle exporté dans: {EXPORT_DIR}\")\n",
    "        \n",
    "        # Vérifier les fichiers créés\n",
    "        if os.path.exists(f\"{EXPORT_DIR}/saved_model\"):\n",
    "            print(\"✅ Dossier saved_model créé\")\n",
    "            saved_model_files = os.listdir(f\"{EXPORT_DIR}/saved_model\")\n",
    "            for file in saved_model_files:\n",
    "                print(f\"   📄 {file}\")\n",
    "        \n",
    "        if os.path.exists(f\"{EXPORT_DIR}/checkpoint\"):\n",
    "            print(\"✅ Checkpoint d'exportation créé\")\n",
    "            \n",
    "        print(\"\\n🎯 Le modèle est maintenant prêt pour l'inférence !\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ ERREUR lors de l'exportation\")\n",
    "        print(f\"Code d'erreur: {result.returncode}\")\n",
    "        if result.stderr:\n",
    "            print(\"Erreurs:\")\n",
    "            print(result.stderr[-1000:])  # Afficher les 1000 derniers caractères\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"⏰ Timeout - L'exportation prend plus de 5 minutes\")\n",
    "    print(\"💡 Essayez de relancer la cellule ou exécutez manuellement la commande\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur: {e}\")\n",
    "\n",
    "print(f\"\\n📋 Résumé:\")\n",
    "print(f\"   🤖 Modèle: SSD MobileNet V2 320x320\")\n",
    "print(f\"   🎯 Classes: Healthy, Contaminated\")\n",
    "print(f\"   📈 Entraînement: 30,000 steps terminés\")\n",
    "print(f\"   💾 Modèle exporté: {EXPORT_DIR}/saved_model\")\n",
    "print(f\"   📊 TensorBoard: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017cbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Script d'inférence créé: ../models/dl_model/outputs/ssd_mnv2_320/mushroom_inference.py\n",
      "\\n📋 Utilisation:\n",
      "   python ../models/dl_model/outputs/ssd_mnv2_320/mushroom_inference.py \\\\\n",
      "     --model ../models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model \\\\\n",
      "     --image chemin/vers/image.jpg \\\\\n",
      "     --output resultat.jpg \\\\\n",
      "     --threshold 0.5\n",
      "\\n💡 Exemple:\n",
      "   python ../models/dl_model/outputs/ssd_mnv2_320/mushroom_inference.py \\\\\n",
      "     --model ../models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model \\\\\n",
      "     --image ../../../images_a_traiter/test_image.jpg \\\\\n",
      "     --output detection_result.jpg\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🔍 SCRIPT D'INFÉRENCE - TESTER LE MODÈLE ENTRAÎNÉ\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "inference_script = f'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script d'inférence pour le modèle SSD MobileNet V2 de détection de champignons\n",
    "Détecte si un champignon est 'Healthy' ou 'Contaminated'\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "class MushroomDetector:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialise le détecteur avec le modèle sauvegardé\"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.class_names = {{1: 'Healthy', 2: 'Contaminated'}}\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Charge le modèle TensorFlow SavedModel\"\"\"\n",
    "        try:\n",
    "            print(f\"📦 Chargement du modèle: {{self.model_path}}\")\n",
    "            self.model = tf.saved_model.load(self.model_path)\n",
    "            self.infer = self.model.signatures['serving_default']\n",
    "            print(\"✅ Modèle chargé avec succès!\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du chargement: {{e}}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_image(self, image_path, target_size=(320, 320)):\n",
    "        \"\"\"Préprocesse l'image pour l'inférence\"\"\"\n",
    "        # Lire l'image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Impossible de lire l'image: {{image_path}}\")\n",
    "        \n",
    "        # Convertir BGR vers RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Redimensionner\n",
    "        image = cv2.resize(image, target_size)\n",
    "        \n",
    "        # Normaliser (0-255 -> 0-1)\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        # Ajouter une dimension batch\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def predict(self, image_path, confidence_threshold=0.5):\n",
    "        \"\"\"Effectue la prédiction sur une image\"\"\"\n",
    "        # Préprocesser l'image\n",
    "        input_tensor = self.preprocess_image(image_path)\n",
    "        input_tensor = tf.constant(input_tensor, dtype=tf.uint8)\n",
    "        \n",
    "        # Faire l'inférence\n",
    "        detections = self.infer(input_tensor)\n",
    "        \n",
    "        # Extraire les résultats\n",
    "        boxes = detections['detection_boxes'][0].numpy()\n",
    "        classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "        scores = detections['detection_scores'][0].numpy()\n",
    "        \n",
    "        # Filtrer par seuil de confiance\n",
    "        valid_detections = scores >= confidence_threshold\n",
    "        \n",
    "        results = []\n",
    "        for i, valid in enumerate(valid_detections):\n",
    "            if valid:\n",
    "                class_id = classes[i]\n",
    "                class_name = self.class_names.get(class_id, f\"Classe_{{class_id}}\")\n",
    "                confidence = scores[i]\n",
    "                box = boxes[i]  # [ymin, xmin, ymax, xmax] normalisé\n",
    "                \n",
    "                results.append({{\n",
    "                    'class_id': class_id,\n",
    "                    'class_name': class_name,\n",
    "                    'confidence': confidence,\n",
    "                    'box': box\n",
    "                }})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_results(self, image_path, results, output_path=None):\n",
    "        \"\"\"Visualise les résultats sur l'image\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        for result in results:\n",
    "            # Convertir les coordonnées normalisées en pixels\n",
    "            ymin, xmin, ymax, xmax = result['box']\n",
    "            xmin = int(xmin * width)\n",
    "            xmax = int(xmax * width)\n",
    "            ymin = int(ymin * height)\n",
    "            ymax = int(ymax * height)\n",
    "            \n",
    "            # Couleur selon la classe\n",
    "            color = (0, 255, 0) if result['class_name'] == 'Healthy' else (0, 0, 255)\n",
    "            \n",
    "            # Dessiner la boîte\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            \n",
    "            # Ajouter le texte\n",
    "            label = f\"{{result['class_name']}}: {{result['confidence']:.2f}}\"\n",
    "            cv2.putText(image, label, (xmin, ymin-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, image)\n",
    "            print(f\"💾 Image sauvée: {{output_path}}\")\n",
    "        else:\n",
    "            cv2.imshow('Détection', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        return image\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Détection de champignons')\n",
    "    parser.add_argument('--model', required=True, help='Chemin vers le modèle SavedModel')\n",
    "    parser.add_argument('--image', required=True, help='Chemin vers l\\\\'image à analyser')\n",
    "    parser.add_argument('--output', help='Chemin de sortie pour l\\\\'image annotée')\n",
    "    parser.add_argument('--threshold', type=float, default=0.5, help='Seuil de confiance')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialiser le détecteur\n",
    "    detector = MushroomDetector(args.model)\n",
    "    \n",
    "    # Faire la prédiction\n",
    "    print(f\"🔍 Analyse de l'image: {{args.image}}\")\n",
    "    results = detector.predict(args.image, args.threshold)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    if results:\n",
    "        print(f\"\\\\n🎯 {{len(results)}} détection(s) trouvée(s):\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"  {{i}}. {{result['class_name']}} ({{result['confidence']:.1%}})\")\n",
    "    else:\n",
    "        print(\"❌ Aucune détection au-dessus du seuil de confiance\")\n",
    "    \n",
    "    # Visualiser si demandé\n",
    "    if args.output or len(results) > 0:\n",
    "        detector.visualize_results(args.image, results, args.output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Sauvegarder le script d'inférence\n",
    "inference_script_path = f\"{OUTPUT_DIR}/mushroom_inference.py\"\n",
    "with open(inference_script_path, 'w') as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "# Rendre le script exécutable\n",
    "os.chmod(inference_script_path, 0o755)\n",
    "\n",
    "print(f\"✅ Script d'inférence créé: {inference_script_path}\")\n",
    "print(f\"\\\\n📋 Utilisation:\")\n",
    "print(f\"   python {inference_script_path} \\\\\\\\\")\n",
    "print(f\"     --model {EXPORT_DIR}/saved_model \\\\\\\\\")\n",
    "print(f\"     --image chemin/vers/image.jpg \\\\\\\\\")\n",
    "print(f\"     --output resultat.jpg \\\\\\\\\")\n",
    "print(f\"     --threshold 0.5\")\n",
    "\n",
    "print(f\"\\\\n💡 Exemple:\")\n",
    "print(f\"   python {inference_script_path} \\\\\\\\\")\n",
    "print(f\"     --model {EXPORT_DIR}/saved_model \\\\\\\\\")\n",
    "print(f\"     --image ../../../images_a_traiter/test_image.jpg \\\\\\\\\")\n",
    "print(f\"     --output detection_result.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa6028",
   "metadata": {},
   "source": [
    "# 🎉 FÉLICITATIONS ! ENTRAÎNEMENT TERMINÉ\n",
    "\n",
    "## ✅ Résumé de l'entraînement réussi :\n",
    "\n",
    "- **Modèle** : SSD MobileNet V2 320x320\n",
    "- **Steps** : 30,000 steps complétés\n",
    "- **Loss finale** : ~0.215 (excellent !)\n",
    "- **GPU utilisé** : RTX 4080 avec succès\n",
    "- **Durée** : ~52 minutes d'entraînement\n",
    "\n",
    "## 🚀 Prochaines étapes :\n",
    "\n",
    "### 1️⃣ **Exporter le modèle**\n",
    "Exécutez la cellule précédente pour exporter le modèle au format SavedModel\n",
    "\n",
    "### 2️⃣ **Tester sur de nouvelles images**\n",
    "```bash\n",
    "# Exemple d'utilisation du script d'inférence\n",
    "python mushroom_inference.py \\\n",
    "  --model exported_model/saved_model \\\n",
    "  --image ../../../../images_a_traiter/test_image.jpg \\\n",
    "  --output resultat_detection.jpg \\\n",
    "  --threshold 0.5\n",
    "```\n",
    "\n",
    "### 3️⃣ **Intégrer dans votre application**\n",
    "- Le modèle exporté peut être utilisé avec TensorFlow Serving\n",
    "- Compatible avec TensorFlow Lite pour mobile\n",
    "- Peut être intégré dans votre API Flask/FastAPI existante\n",
    "\n",
    "## 📊 Analyser les performances :\n",
    "\n",
    "- **TensorBoard** : http://localhost:6006\n",
    "- **Checkpoints** : Sauvés automatiquement toutes les 1000 steps\n",
    "- **Métriques** : Loss de classification et localisation convergent bien\n",
    "\n",
    "## 🎯 Classes détectées :\n",
    "\n",
    "1. **Healthy** : Champignons sains\n",
    "2. **Contaminated** : Champignons contaminés\n",
    "\n",
    "## 💡 Optimisations possibles :\n",
    "\n",
    "- **Augmentation des données** : Rotation, flip, contraste\n",
    "- **Hyperparamètres** : Ajuster learning rate, batch size\n",
    "- **Architecture** : Tester EfficientDet, YOLOv8\n",
    "- **Post-processing** : Ajuster NMS threshold\n",
    "\n",
    "## 🔧 Troubleshooting :\n",
    "\n",
    "Si vous rencontrez des problèmes :\n",
    "1. Vérifiez que TensorBoard affiche bien les métriques\n",
    "2. Consultez les logs d'entraînement pour détecter des erreurs\n",
    "3. Testez l'inférence sur quelques images de validation\n",
    "\n",
    "---\n",
    "\n",
    "**🎊 Votre modèle de détection de champignons est maintenant prêt à l'emploi !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aad330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test du modèle entraîné sur les données de test...\n",
      "✅ Données de test trouvées: ../data/DL_data/test\n",
      "✅ Annotations: ../data/DL_data/test/_annotations.csv\n",
      "✅ Modèle: ../models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model\n",
      "📦 Chargement du modèle...\n",
      "✅ Modèle chargé avec succès!\n",
      "📊 Lecture des annotations de test...\n",
      "📈 Dataset de test: 532 annotations, 394 images uniques\n",
      "📋 Classes dans le test: {'Healthy': 305, 'Contaminated': 227}\n",
      "\\n🚀 Démarrage de l'évaluation...\n",
      "🔍 Évaluation sur 394 images de test...\n",
      "   Seuil de confiance: 0.5\n",
      "   Seuil IoU: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 02:09:14.678539: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️  Temps d'inférence moyen: 0.016s par image\n",
      "\\n📊 Résultats de l'évaluation:\n",
      "   Total d'évaluations: 532\n",
      "   True Positives (TP): 510\n",
      "   False Positives (FP): 1\n",
      "   False Negatives (FN): 21\n",
      "\\n🎯 Métriques de performance:\n",
      "   Précision: 0.998 (99.8%)\n",
      "   Rappel: 0.960 (96.0%)\n",
      "   F1-Score: 0.979\n",
      "\\n📈 Performance par classe:\n",
      "   Healthy:\n",
      "     Précision: 1.000 (100.0%)\n",
      "     Rappel: 0.957 (95.7%)\n",
      "     F1-Score: 0.978\n",
      "   Contaminated:\n",
      "     Précision: 0.995 (99.5%)\n",
      "     Rappel: 0.965 (96.5%)\n",
      "     F1-Score: 0.980\n",
      "\\n💪 Confiance moyenne des prédictions: 0.817 (81.7%)\n",
      "\\n✅ Évaluation terminée avec succès!\n",
      "📊 DataFrame 'results_df' disponible pour analyse détaillée\n",
      "\\n💾 Variables créées:\n",
      "   - test_df: DataFrame des annotations de test\n",
      "   - results_df: DataFrame des résultats d'évaluation\n",
      "   - tester: Instance du testeur pour analyses supplémentaires\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 🧪 TEST DU MODÈLE SUR LES DONNÉES DE TEST\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "print(\"🧪 Test du modèle entraîné sur les données de test...\")\n",
    "\n",
    "# Chemins vers les données de test\n",
    "TEST_DIR = \"../data/DL_data/test\"\n",
    "TEST_ANN = f\"{TEST_DIR}/_annotations.csv\"\n",
    "SAVED_MODEL_PATH = f\"{EXPORT_DIR}/saved_model\"\n",
    "\n",
    "# Vérification des fichiers\n",
    "if not os.path.exists(TEST_ANN):\n",
    "    print(f\"❌ Fichier d'annotations de test introuvable: {TEST_ANN}\")\n",
    "    raise FileNotFoundError(f\"Annotations de test manquantes: {TEST_ANN}\")\n",
    "\n",
    "if not os.path.exists(SAVED_MODEL_PATH):\n",
    "    print(f\"❌ Modèle exporté introuvable: {SAVED_MODEL_PATH}\")\n",
    "    print(\"💡 Exécutez d'abord la cellule d'exportation du modèle\")\n",
    "    raise FileNotFoundError(f\"Modèle exporté manquant: {SAVED_MODEL_PATH}\")\n",
    "\n",
    "print(f\"✅ Données de test trouvées: {TEST_DIR}\")\n",
    "print(f\"✅ Annotations: {TEST_ANN}\")\n",
    "print(f\"✅ Modèle: {SAVED_MODEL_PATH}\")\n",
    "\n",
    "# Chargement du modèle\n",
    "print(\"📦 Chargement du modèle...\")\n",
    "model = tf.saved_model.load(SAVED_MODEL_PATH)\n",
    "infer_fn = model.signatures['serving_default']\n",
    "print(\"✅ Modèle chargé avec succès!\")\n",
    "\n",
    "# Lecture des annotations de test\n",
    "print(\"📊 Lecture des annotations de test...\")\n",
    "test_df = pd.read_csv(TEST_ANN)\n",
    "print(f\"📈 Dataset de test: {len(test_df)} annotations, {test_df['filename'].nunique()} images uniques\")\n",
    "print(f\"📋 Classes dans le test: {test_df['class'].value_counts().to_dict()}\")\n",
    "\n",
    "# Classe de détection\n",
    "class MushroomTester:\n",
    "    def __init__(self, model_fn, class_names={1: 'Healthy', 2: 'Contaminated'}):\n",
    "        self.model_fn = model_fn\n",
    "        self.class_names = class_names\n",
    "        self.results = []\n",
    "    \n",
    "    def preprocess_image(self, image_path, target_size=(320, 320)):\n",
    "        \"\"\"Préprocesse l'image pour l'inférence\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Impossible de lire l'image: {image_path}\")\n",
    "        \n",
    "        # Convertir BGR vers RGB et redimensionner\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, target_size)\n",
    "        \n",
    "        # Convertir en uint8 et ajouter dimension batch\n",
    "        image = image.astype(np.uint8)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def predict_image(self, image_path, confidence_threshold=0.5):\n",
    "        \"\"\"Prédit sur une seule image\"\"\"\n",
    "        try:\n",
    "            # Préprocesser\n",
    "            input_tensor = self.preprocess_image(image_path)\n",
    "            input_tensor = tf.constant(input_tensor, dtype=tf.uint8)\n",
    "            \n",
    "            # Inférence\n",
    "            start_time = time.time()\n",
    "            detections = self.model_fn(input_tensor)\n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            # Extraire résultats\n",
    "            boxes = detections['detection_boxes'][0].numpy()\n",
    "            classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "            scores = detections['detection_scores'][0].numpy()\n",
    "            \n",
    "            # Filtrer par confiance\n",
    "            valid_detections = scores >= confidence_threshold\n",
    "            \n",
    "            predictions = []\n",
    "            for i, valid in enumerate(valid_detections):\n",
    "                if valid:\n",
    "                    predictions.append({\n",
    "                        'class_id': classes[i],\n",
    "                        'class_name': self.class_names.get(classes[i], f\"Class_{classes[i]}\"),\n",
    "                        'confidence': scores[i],\n",
    "                        'box': boxes[i]  # [ymin, xmin, ymax, xmax]\n",
    "                    })\n",
    "            \n",
    "            return predictions, inference_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors de la prédiction pour {image_path}: {e}\")\n",
    "            return [], 0.0\n",
    "    \n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"Calcule l'IoU entre deux boîtes [ymin, xmin, ymax, xmax]\"\"\"\n",
    "        # Coordonnées d'intersection\n",
    "        y1 = max(box1[0], box2[0])\n",
    "        x1 = max(box1[1], box2[1])\n",
    "        y2 = min(box1[2], box2[2])\n",
    "        x2 = min(box1[3], box2[3])\n",
    "        \n",
    "        # Aire d'intersection\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = (x2 - x1) * (y2 - y1)\n",
    "        \n",
    "        # Aires des boîtes\n",
    "        area1 = (box1[3] - box1[1]) * (box1[2] - box1[0])\n",
    "        area2 = (box2[3] - box2[1]) * (box2[2] - box2[0])\n",
    "        \n",
    "        # IoU\n",
    "        union = area1 + area2 - intersection\n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def evaluate_on_test_set(self, test_df, test_dir, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "        \"\"\"Évalue le modèle sur le dataset de test complet\"\"\"\n",
    "        print(f\"🔍 Évaluation sur {test_df['filename'].nunique()} images de test...\")\n",
    "        print(f\"   Seuil de confiance: {confidence_threshold}\")\n",
    "        print(f\"   Seuil IoU: {iou_threshold}\")\n",
    "        \n",
    "        results = []\n",
    "        total_inference_time = 0\n",
    "        \n",
    "        # Grouper par image\n",
    "        for filename, group in test_df.groupby('filename'):\n",
    "            image_path = os.path.join(test_dir, filename)\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"⚠️  Image manquante: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Prédictions du modèle\n",
    "            predictions, inf_time = self.predict_image(image_path, confidence_threshold)\n",
    "            total_inference_time += inf_time\n",
    "            \n",
    "            # Vérités terrain (ground truth)\n",
    "            gt_boxes = []\n",
    "            for _, row in group.iterrows():\n",
    "                # Normaliser les coordonnées ground truth\n",
    "                gt_box = [\n",
    "                    row['ymin'] / row['height'],  # ymin\n",
    "                    row['xmin'] / row['width'],   # xmin\n",
    "                    row['ymax'] / row['height'],  # ymax\n",
    "                    row['xmax'] / row['width']    # xmax\n",
    "                ]\n",
    "                gt_boxes.append({\n",
    "                    'box': gt_box,\n",
    "                    'class_name': row['class'],\n",
    "                    'class_id': 1 if row['class'] == 'Healthy' else 2\n",
    "                })\n",
    "            \n",
    "            # Associer prédictions et ground truth\n",
    "            for gt in gt_boxes:\n",
    "                best_iou = 0\n",
    "                best_pred = None\n",
    "                \n",
    "                for pred in predictions:\n",
    "                    iou = self.calculate_iou(gt['box'], pred['box'])\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_pred = pred\n",
    "                \n",
    "                # Déterminer si c'est un TP, FP, ou FN\n",
    "                if best_iou >= iou_threshold and best_pred:\n",
    "                    # True Positive si même classe\n",
    "                    is_correct = (gt['class_id'] == best_pred['class_id'])\n",
    "                    results.append({\n",
    "                        'filename': filename,\n",
    "                        'gt_class': gt['class_name'],\n",
    "                        'pred_class': best_pred['class_name'],\n",
    "                        'confidence': best_pred['confidence'],\n",
    "                        'iou': best_iou,\n",
    "                        'type': 'TP' if is_correct else 'FP',\n",
    "                        'inference_time': inf_time\n",
    "                    })\n",
    "                else:\n",
    "                    # False Negative\n",
    "                    results.append({\n",
    "                        'filename': filename,\n",
    "                        'gt_class': gt['class_name'],\n",
    "                        'pred_class': 'None',\n",
    "                        'confidence': 0.0,\n",
    "                        'iou': 0.0,\n",
    "                        'type': 'FN',\n",
    "                        'inference_time': inf_time\n",
    "                    })\n",
    "            \n",
    "            # False Positives (prédictions sans correspondance GT)\n",
    "            for pred in predictions:\n",
    "                has_match = False\n",
    "                for gt in gt_boxes:\n",
    "                    if self.calculate_iou(gt['box'], pred['box']) >= iou_threshold:\n",
    "                        has_match = True\n",
    "                        break\n",
    "                \n",
    "                if not has_match:\n",
    "                    results.append({\n",
    "                        'filename': filename,\n",
    "                        'gt_class': 'None',\n",
    "                        'pred_class': pred['class_name'],\n",
    "                        'confidence': pred['confidence'],\n",
    "                        'iou': 0.0,\n",
    "                        'type': 'FP',\n",
    "                        'inference_time': inf_time\n",
    "                    })\n",
    "        \n",
    "        self.results = results\n",
    "        \n",
    "        # Statistiques\n",
    "        avg_inference_time = total_inference_time / len(test_df['filename'].unique())\n",
    "        print(f\"⏱️  Temps d'inférence moyen: {avg_inference_time:.3f}s par image\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialisation du testeur\n",
    "tester = MushroomTester(infer_fn)\n",
    "\n",
    "# Exécution des tests\n",
    "print(\"\\\\n🚀 Démarrage de l'évaluation...\")\n",
    "test_results = tester.evaluate_on_test_set(test_df, TEST_DIR, confidence_threshold=0.5, iou_threshold=0.5)\n",
    "\n",
    "# Conversion en DataFrame pour l'analyse\n",
    "results_df = pd.DataFrame(test_results)\n",
    "\n",
    "print(f\"\\\\n📊 Résultats de l'évaluation:\")\n",
    "print(f\"   Total d'évaluations: {len(results_df)}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    type_counts = results_df['type'].value_counts()\n",
    "    print(f\"   True Positives (TP): {type_counts.get('TP', 0)}\")\n",
    "    print(f\"   False Positives (FP): {type_counts.get('FP', 0)}\")\n",
    "    print(f\"   False Negatives (FN): {type_counts.get('FN', 0)}\")\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    tp = type_counts.get('TP', 0)\n",
    "    fp = type_counts.get('FP', 0)\n",
    "    fn = type_counts.get('FN', 0)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\\\n🎯 Métriques de performance:\")\n",
    "    print(f\"   Précision: {precision:.3f} ({precision*100:.1f}%)\")\n",
    "    print(f\"   Rappel: {recall:.3f} ({recall*100:.1f}%)\")\n",
    "    print(f\"   F1-Score: {f1_score:.3f}\")\n",
    "    \n",
    "    # Métriques par classe\n",
    "    print(f\"\\\\n📈 Performance par classe:\")\n",
    "    for class_name in ['Healthy', 'Contaminated']:\n",
    "        class_tp = len(results_df[(results_df['gt_class'] == class_name) & (results_df['type'] == 'TP')])\n",
    "        class_fp = len(results_df[(results_df['pred_class'] == class_name) & (results_df['type'] == 'FP')])\n",
    "        class_fn = len(results_df[(results_df['gt_class'] == class_name) & (results_df['type'] == 'FN')])\n",
    "        \n",
    "        class_precision = class_tp / (class_tp + class_fp) if (class_tp + class_fp) > 0 else 0\n",
    "        class_recall = class_tp / (class_tp + class_fn) if (class_tp + class_fn) > 0 else 0\n",
    "        class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "        \n",
    "        print(f\"   {class_name}:\")\n",
    "        print(f\"     Précision: {class_precision:.3f} ({class_precision*100:.1f}%)\")\n",
    "        print(f\"     Rappel: {class_recall:.3f} ({class_recall*100:.1f}%)\")\n",
    "        print(f\"     F1-Score: {class_f1:.3f}\")\n",
    "    \n",
    "    # Confiance moyenne\n",
    "    if len(results_df[results_df['confidence'] > 0]) > 0:\n",
    "        avg_confidence = results_df[results_df['confidence'] > 0]['confidence'].mean()\n",
    "        print(f\"\\\\n💪 Confiance moyenne des prédictions: {avg_confidence:.3f} ({avg_confidence*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\\\n✅ Évaluation terminée avec succès!\")\n",
    "    print(f\"📊 DataFrame 'results_df' disponible pour analyse détaillée\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Aucun résultat d'évaluation trouvé\")\n",
    "\n",
    "print(f\"\\\\n💾 Variables créées:\")\n",
    "print(f\"   - test_df: DataFrame des annotations de test\")\n",
    "print(f\"   - results_df: DataFrame des résultats d'évaluation\")\n",
    "print(f\"   - tester: Instance du testeur pour analyses supplémentaires\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Création des visualisations des résultats...\n",
      "\\n🖼️  Affichage d'exemples de prédictions...\n",
      "\\n📊 Tableau récapitulatif des performances:\n",
      "============================================================\n",
      "🎯 PERFORMANCE GLOBALE:\n",
      "   Précision: 0.998 (99.8%)\n",
      "   Rappel: 0.960 (96.0%)\n",
      "   F1-Score: 0.979\n",
      "   Détections correctes: 510/531\n",
      "\\n📈 DÉTAILS:\n",
      "   True Positives: 510\n",
      "   False Positives: 1\n",
      "   False Negatives: 21\n",
      "   Temps moyen d'inférence: 0.015s par image\n",
      "============================================================\n",
      "\\n✅ Visualisation terminée!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_533743/2755555373.py:84: UserWarning: Glyph 129514 (\\N{TEST TUBE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_533743/2755555373.py:85: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_533743/2755555373.py:168: UserWarning: Glyph 128444 (\\N{FRAME WITH PICTURE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_533743/2755555373.py:169: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# 📈 VISUALISATION DES RÉSULTATS ET EXEMPLES\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "\n",
    "print(\"📈 Création des visualisations des résultats...\")\n",
    "\n",
    "# Configuration de matplotlib\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Vérifier si nous avons des résultats\n",
    "if 'results_df' in locals() and len(results_df) > 0:\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    # 📊 GRAPHIQUES DE PERFORMANCE\n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('🧪 Résultats des Tests du Modèle SSD MobileNet V2', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Distribution des types de résultats\n",
    "    ax1 = axes[0, 0]\n",
    "    type_counts = results_df['type'].value_counts()\n",
    "    colors = ['#2ecc71', '#e74c3c', '#f39c12']  # Vert, Rouge, Orange\n",
    "    wedges, texts, autotexts = ax1.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', \n",
    "                                       colors=colors, startangle=90)\n",
    "    ax1.set_title('Distribution des Résultats\\\\n(TP/FP/FN)', fontweight='bold')\n",
    "    \n",
    "    # 2. Distribution des confiances\n",
    "    ax2 = axes[0, 1]\n",
    "    confident_preds = results_df[results_df['confidence'] > 0]['confidence']\n",
    "    if len(confident_preds) > 0:\n",
    "        ax2.hist(confident_preds, bins=20, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "        ax2.axvline(confident_preds.mean(), color='red', linestyle='--', \n",
    "                   label=f'Moyenne: {confident_preds.mean():.3f}')\n",
    "        ax2.set_xlabel('Confiance')\n",
    "        ax2.set_ylabel('Nombre de prédictions')\n",
    "        ax2.set_title('Distribution des Confiances', fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Performance par classe\n",
    "    ax3 = axes[1, 0]\n",
    "    class_metrics = {}\n",
    "    for class_name in ['Healthy', 'Contaminated']:\n",
    "        tp = len(results_df[(results_df['gt_class'] == class_name) & (results_df['type'] == 'TP')])\n",
    "        fp = len(results_df[(results_df['pred_class'] == class_name) & (results_df['type'] == 'FP')])\n",
    "        fn = len(results_df[(results_df['gt_class'] == class_name) & (results_df['type'] == 'FN')])\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        class_metrics[class_name] = {'Précision': precision, 'Rappel': recall, 'F1-Score': f1}\n",
    "    \n",
    "    # Graphique en barres pour les métriques par classe\n",
    "    metrics_df = pd.DataFrame(class_metrics).T\n",
    "    metrics_df.plot(kind='bar', ax=ax3, width=0.8)\n",
    "    ax3.set_title('Métriques par Classe', fontweight='bold')\n",
    "    ax3.set_ylabel('Score')\n",
    "    ax3.set_xlabel('Classe')\n",
    "    ax3.legend(loc='upper right')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    # 4. Distribution des IoU pour les TP\n",
    "    ax4 = axes[1, 1]\n",
    "    tp_ious = results_df[results_df['type'] == 'TP']['iou']\n",
    "    if len(tp_ious) > 0:\n",
    "        ax4.hist(tp_ious, bins=15, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "        ax4.axvline(tp_ious.mean(), color='red', linestyle='--', \n",
    "                   label=f'Moyenne: {tp_ious.mean():.3f}')\n",
    "        ax4.set_xlabel('IoU')\n",
    "        ax4.set_ylabel('Nombre de TP')\n",
    "        ax4.set_title('Distribution des IoU (True Positives)', fontweight='bold')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    # 🖼️ EXEMPLES DE PRÉDICTIONS\n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    \n",
    "    print(\"\\\\n🖼️  Affichage d'exemples de prédictions...\")\n",
    "    \n",
    "    def show_prediction_examples(results_df, test_dir, num_examples=6):\n",
    "        \"\"\"Affiche des exemples de prédictions avec les images\"\"\"\n",
    "        \n",
    "        # Sélectionner des exemples variés\n",
    "        examples = []\n",
    "        \n",
    "        # Quelques TP de chaque classe\n",
    "        tp_healthy = results_df[(results_df['type'] == 'TP') & (results_df['gt_class'] == 'Healthy')]\n",
    "        tp_contaminated = results_df[(results_df['type'] == 'TP') & (results_df['gt_class'] == 'Contaminated')]\n",
    "        \n",
    "        # Quelques erreurs\n",
    "        fp_examples = results_df[results_df['type'] == 'FP']\n",
    "        fn_examples = results_df[results_df['type'] == 'FN']\n",
    "        \n",
    "        # Sélection équilibrée\n",
    "        if len(tp_healthy) > 0:\n",
    "            examples.append(tp_healthy.iloc[0])\n",
    "        if len(tp_contaminated) > 0:\n",
    "            examples.append(tp_contaminated.iloc[0])\n",
    "        if len(fp_examples) > 0:\n",
    "            examples.append(fp_examples.iloc[0])\n",
    "        if len(fn_examples) > 0:\n",
    "            examples.append(fn_examples.iloc[0])\n",
    "        \n",
    "        # Compléter avec des exemples aléatoires\n",
    "        remaining = results_df.sample(min(num_examples - len(examples), len(results_df)))\n",
    "        for _, row in remaining.iterrows():\n",
    "            if len(examples) < num_examples and row.name not in [ex.name for ex in examples]:\n",
    "                examples.append(row)\n",
    "        \n",
    "        # Créer la figure\n",
    "        n_examples = min(len(examples), num_examples)\n",
    "        cols = 3\n",
    "        rows = (n_examples + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "        if rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, example in enumerate(examples[:num_examples]):\n",
    "            row, col = i // cols, i % cols\n",
    "            ax = axes[row, col] if rows > 1 else axes[col]\n",
    "            \n",
    "            # Charger et afficher l'image\n",
    "            image_path = os.path.join(test_dir, example['filename'])\n",
    "            if os.path.exists(image_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                ax.imshow(image)\n",
    "                \n",
    "                # Titre avec les informations\n",
    "                title = f\"{example['type']}: {example['filename'][:20]}...\"\n",
    "                if example['gt_class'] != 'None':\n",
    "                    title += f\"\\\\nGT: {example['gt_class']}\"\n",
    "                if example['pred_class'] != 'None':\n",
    "                    title += f\" | Pred: {example['pred_class']} ({example['confidence']:.2f})\"\n",
    "                if example['iou'] > 0:\n",
    "                    title += f\"\\\\nIoU: {example['iou']:.3f}\"\n",
    "                \n",
    "                # Couleur du titre selon le type\n",
    "                title_color = {'TP': 'green', 'FP': 'red', 'FN': 'orange'}.get(example['type'], 'black')\n",
    "                ax.set_title(title, fontsize=10, color=title_color, fontweight='bold')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"Image\\\\n{example['filename']}\\\\nnon trouvée\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "            \n",
    "            ax.axis('off')\n",
    "        \n",
    "        # Masquer les axes vides\n",
    "        for i in range(n_examples, rows * cols):\n",
    "            row, col = i // cols, i % cols\n",
    "            ax = axes[row, col] if rows > 1 else axes[col]\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle('🖼️ Exemples de Prédictions du Modèle', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Afficher les exemples\n",
    "    show_prediction_examples(results_df, TEST_DIR, num_examples=6)\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    # 📊 TABLEAU RÉCAPITULATIF\n",
    "    # ═══════════════════════════════════════════════════════════\n",
    "    \n",
    "    print(\"\\\\n📊 Tableau récapitulatif des performances:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculs globaux\n",
    "    tp_total = len(results_df[results_df['type'] == 'TP'])\n",
    "    fp_total = len(results_df[results_df['type'] == 'FP'])\n",
    "    fn_total = len(results_df[results_df['type'] == 'FN'])\n",
    "    \n",
    "    precision_global = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
    "    recall_global = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
    "    f1_global = 2 * (precision_global * recall_global) / (precision_global + recall_global) if (precision_global + recall_global) > 0 else 0\n",
    "    \n",
    "    print(f\"🎯 PERFORMANCE GLOBALE:\")\n",
    "    print(f\"   Précision: {precision_global:.3f} ({precision_global*100:.1f}%)\")\n",
    "    print(f\"   Rappel: {recall_global:.3f} ({recall_global*100:.1f}%)\")\n",
    "    print(f\"   F1-Score: {f1_global:.3f}\")\n",
    "    print(f\"   Détections correctes: {tp_total}/{tp_total + fn_total}\")\n",
    "    \n",
    "    print(f\"\\\\n📈 DÉTAILS:\")\n",
    "    print(f\"   True Positives: {tp_total}\")\n",
    "    print(f\"   False Positives: {fp_total}\")\n",
    "    print(f\"   False Negatives: {fn_total}\")\n",
    "    \n",
    "    # Temps d'inférence\n",
    "    if 'inference_time' in results_df.columns:\n",
    "        avg_time = results_df['inference_time'].mean()\n",
    "        print(f\"   Temps moyen d'inférence: {avg_time:.3f}s par image\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Aucun résultat à visualiser. Exécutez d'abord la cellule de test précédente.\")\n",
    "\n",
    "print(\"\\\\n✅ Visualisation terminée!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
