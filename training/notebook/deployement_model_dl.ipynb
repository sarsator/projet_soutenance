{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a587b5c",
   "metadata": {},
   "source": [
    "# ğŸš€ DÃ©ploiement du ModÃ¨le SSD MobileNet V2\n",
    "\n",
    "Ce notebook automatise le dÃ©ploiement du modÃ¨le SSD MobileNet V2 entraÃ®nÃ© vers le systÃ¨me de versioning de l'API.\n",
    "\n",
    "## ğŸ“‹ Processus de dÃ©ploiement\n",
    "\n",
    "1. **Analyse du modÃ¨le** : VÃ©rification du modÃ¨le SavedModel\n",
    "2. **Versioning automatique** : IncrÃ©mentation intelligente de la version\n",
    "3. **Copie et mÃ©tadonnÃ©es** : DÃ©ploiement avec informations complÃ¨tes\n",
    "4. **Validation** : Test du modÃ¨le dÃ©ployÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07caf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:25:11.048155: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 13:25:11.072481: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 13:25:11.072515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 13:25:11.073274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 13:25:11.078016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-16 13:25:11.819337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuration du dÃ©ploiement\n",
      "ğŸ“ ModÃ¨le source: /home/sarsator/projets/gaia_vision/training/models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model\n",
      "ğŸ“ Destination API: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions\n",
      "ğŸ“ Notebook source: /home/sarsator/projets/gaia_vision/training/notebook/dl_finetuning.ipynb\n",
      "âœ… Tous les chemins sont valides!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Configuration des chemins\n",
    "TRAINING_MODEL_PATH = \"/home/sarsator/projets/gaia_vision/training/models/dl_model/outputs/ssd_mnv2_320/exported_model/saved_model\"\n",
    "API_VERSIONS_PATH = \"/home/sarsator/projets/gaia_vision/api/models/dl_model/versions\"\n",
    "TRAINING_NOTEBOOK_PATH = \"/home/sarsator/projets/gaia_vision/training/notebook/dl_finetuning.ipynb\"\n",
    "\n",
    "print(\"ğŸ”§ Configuration du dÃ©ploiement\")\n",
    "print(f\"ğŸ“ ModÃ¨le source: {TRAINING_MODEL_PATH}\")\n",
    "print(f\"ğŸ“ Destination API: {API_VERSIONS_PATH}\")\n",
    "print(f\"ğŸ“ Notebook source: {TRAINING_NOTEBOOK_PATH}\")\n",
    "\n",
    "# VÃ©rification des chemins\n",
    "assert os.path.exists(TRAINING_MODEL_PATH), f\"âŒ ModÃ¨le source non trouvÃ©: {TRAINING_MODEL_PATH}\"\n",
    "assert os.path.exists(API_VERSIONS_PATH), f\"âŒ Dossier de versions non trouvÃ©: {API_VERSIONS_PATH}\"\n",
    "assert os.path.exists(TRAINING_NOTEBOOK_PATH), f\"âŒ Notebook source non trouvÃ©: {TRAINING_NOTEBOOK_PATH}\"\n",
    "\n",
    "print(\"âœ… Tous les chemins sont valides!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5205d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Versions existantes trouvÃ©es:\n",
      "   â””â”€â”€ v1.0_20250711_143245\n",
      "   â””â”€â”€ v1.1_20250711_143319\n",
      "   â””â”€â”€ v1.2_20250711_143350\n",
      "ğŸ” DerniÃ¨re version: v1.2\n",
      "ğŸ†• Nouvelle version: v1.3_20250716_132518\n"
     ]
    }
   ],
   "source": [
    "def get_next_version():\n",
    "    \"\"\"Analyse les versions existantes et retourne la prochaine version Ã  utiliser\"\"\"\n",
    "    \n",
    "    if not os.path.exists(API_VERSIONS_PATH):\n",
    "        return \"1.0\", \"20250716_000000\"\n",
    "    \n",
    "    # Lister toutes les versions existantes\n",
    "    versions = []\n",
    "    for folder in os.listdir(API_VERSIONS_PATH):\n",
    "        if os.path.isdir(os.path.join(API_VERSIONS_PATH, folder)):\n",
    "            # Format attendu: v1.2_20250711_143350\n",
    "            match = re.match(r'v(\\d+)\\.(\\d+)_(\\d{8}_\\d{6})', folder)\n",
    "            if match:\n",
    "                major, minor, timestamp = match.groups()\n",
    "                versions.append((int(major), int(minor), timestamp, folder))\n",
    "    \n",
    "    if not versions:\n",
    "        return \"1.0\", \"20250716_000000\"\n",
    "    \n",
    "    # Trier par version (major, minor)\n",
    "    versions.sort(key=lambda x: (x[0], x[1]))\n",
    "    latest_major, latest_minor, _, latest_folder = versions[-1]\n",
    "    \n",
    "    print(f\"ğŸ“‹ Versions existantes trouvÃ©es:\")\n",
    "    for major, minor, timestamp, folder in versions:\n",
    "        print(f\"   â””â”€â”€ v{major}.{minor}_{timestamp}\")\n",
    "    \n",
    "    print(f\"ğŸ” DerniÃ¨re version: v{latest_major}.{latest_minor}\")\n",
    "    \n",
    "    # IncrÃ©menter la version mineure\n",
    "    next_version = f\"{latest_major}.{latest_minor + 1}\"\n",
    "    next_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"ğŸ†• Nouvelle version: v{next_version}_{next_timestamp}\")\n",
    "    \n",
    "    return next_version, next_timestamp\n",
    "\n",
    "# Test de la fonction\n",
    "next_version, next_timestamp = get_next_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ceb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Analyse du modÃ¨le SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:25:22.451643: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.521034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.521069: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.522598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.522624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.522636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.650126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.650177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.650183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-07-16 13:25:22.650204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-16 13:25:22.650225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13512 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:02:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le chargÃ© avec succÃ¨s\n",
      "ğŸ“‹ Signatures disponibles: ['serving_default']\n",
      "\n",
      "ğŸ”§ Analyse de la signature 'serving_default':\n",
      "   ğŸ“¥ Inputs:\n",
      "      â””â”€â”€ input_tensor: (1, None, None, 3) (<dtype: 'uint8'>)\n",
      "   ğŸ“¤ Outputs:\n",
      "      â””â”€â”€ raw_detection_boxes: (1, 2034, 4) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ detection_multiclass_scores: (1, 100, 3) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ detection_classes: (1, 100) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ detection_boxes: (1, 100, 4) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ raw_detection_scores: (1, 2034, 3) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ num_detections: (1,) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ detection_anchor_indices: (1, 100) (<dtype: 'float32'>)\n",
      "      â””â”€â”€ detection_scores: (1, 100) (<dtype: 'float32'>)\n",
      "\n",
      "ğŸ“ Taille du modÃ¨le: 22.83 MB (23936569 bytes)\n"
     ]
    }
   ],
   "source": [
    "def analyze_savedmodel():\n",
    "    \"\"\"Analyse le modÃ¨le SavedModel et retourne ses informations\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” Analyse du modÃ¨le SavedModel...\")\n",
    "    \n",
    "    # Charger le modÃ¨le\n",
    "    try:\n",
    "        model = tf.saved_model.load(TRAINING_MODEL_PATH)\n",
    "        print(\"âœ… ModÃ¨le chargÃ© avec succÃ¨s\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Analyser les signatures\n",
    "    signatures = list(model.signatures.keys())\n",
    "    print(f\"ğŸ“‹ Signatures disponibles: {signatures}\")\n",
    "    \n",
    "    # Analyser la signature principale (gÃ©nÃ©ralement 'serving_default')\n",
    "    if 'serving_default' in signatures:\n",
    "        serving_fn = model.signatures['serving_default']\n",
    "        \n",
    "        print(\"\\nğŸ”§ Analyse de la signature 'serving_default':\")\n",
    "        print(\"   ğŸ“¥ Inputs:\")\n",
    "        for name, spec in serving_fn.structured_input_signature[1].items():\n",
    "            print(f\"      â””â”€â”€ {name}: {spec.shape} ({spec.dtype})\")\n",
    "        \n",
    "        print(\"   ğŸ“¤ Outputs:\")\n",
    "        for name, spec in serving_fn.structured_outputs.items():\n",
    "            print(f\"      â””â”€â”€ {name}: {spec.shape} ({spec.dtype})\")\n",
    "    \n",
    "    # Calculer la taille du modÃ¨le\n",
    "    total_size = 0\n",
    "    for root, dirs, files in os.walk(TRAINING_MODEL_PATH):\n",
    "        for file in files:\n",
    "            total_size += os.path.getsize(os.path.join(root, file))\n",
    "    \n",
    "    size_mb = total_size / (1024 * 1024)\n",
    "    print(f\"\\nğŸ“ Taille du modÃ¨le: {size_mb:.2f} MB ({total_size} bytes)\")\n",
    "    \n",
    "    model_info = {\n",
    "        'signatures': signatures,\n",
    "        'size_bytes': total_size,\n",
    "        'size_mb': round(size_mb, 2),\n",
    "        'architecture': 'SSD_MobileNet_V2_320x320',\n",
    "        'framework': 'TensorFlow_Object_Detection_API'\n",
    "    }\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "# Analyser le modÃ¨le\n",
    "model_info = analyze_savedmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08191cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ PrÃªt pour le dÃ©ploiement!\n"
     ]
    }
   ],
   "source": [
    "def deploy_model(version, timestamp, model_info):\n",
    "    \"\"\"DÃ©ploie le modÃ¨le avec versioning automatique\"\"\"\n",
    "    \n",
    "    # CrÃ©er le nom du dossier de destination\n",
    "    version_folder = f\"v{version}_{timestamp}\"\n",
    "    destination_path = os.path.join(API_VERSIONS_PATH, version_folder)\n",
    "    \n",
    "    print(f\"ğŸš€ DÃ©ploiement vers: {destination_path}\")\n",
    "    \n",
    "    # CrÃ©er le dossier de destination\n",
    "    os.makedirs(destination_path, exist_ok=True)\n",
    "    \n",
    "    # Copier le modÃ¨le SavedModel\n",
    "    model_dest_path = os.path.join(destination_path, \"saved_model\")\n",
    "    print(f\"ğŸ“ Copie du modÃ¨le SavedModel...\")\n",
    "    \n",
    "    if os.path.exists(model_dest_path):\n",
    "        shutil.rmtree(model_dest_path)\n",
    "    \n",
    "    shutil.copytree(TRAINING_MODEL_PATH, model_dest_path)\n",
    "    print(f\"âœ… ModÃ¨le copiÃ© vers: {model_dest_path}\")\n",
    "    \n",
    "    # CrÃ©er les mÃ©tadonnÃ©es\n",
    "    metadata = {\n",
    "        \"version\": version,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model_type\": \"deep_learning_object_detection\",\n",
    "        \"deployed_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"deployment_id\": timestamp,\n",
    "        \"model_size_mb\": model_info['size_mb'],\n",
    "        \"model_size_bytes\": model_info['size_bytes'],\n",
    "        \"architecture\": model_info['architecture'],\n",
    "        \"framework\": model_info['framework'],\n",
    "        \"signatures\": model_info['signatures'],\n",
    "        \"deployed_by\": \"automated_deployment_notebook\",\n",
    "        \"training_notebook\": \"dl_finetuning.ipynb\",\n",
    "        \"source_path\": TRAINING_MODEL_PATH,\n",
    "        \"deployment_type\": \"production_savedmodel\",\n",
    "        \"model_format\": \"tensorflow_savedmodel\",\n",
    "        \"deployed_path\": model_dest_path,\n",
    "        \"performance_metrics\": {\n",
    "            \"precision\": 99.8,\n",
    "            \"recall\": 96.0,\n",
    "            \"f1_score\": 97.9,\n",
    "            \"inference_time_ms\": 16,\n",
    "            \"test_images\": 394,\n",
    "            \"training_steps\": 30000\n",
    "        },\n",
    "        \"model_capabilities\": [\n",
    "            \"mushroom_detection\",\n",
    "            \"contamination_classification\", \n",
    "            \"real_time_inference\",\n",
    "            \"batch_processing\"\n",
    "        ],\n",
    "        \"input_specifications\": {\n",
    "            \"image_size\": \"320x320\",\n",
    "            \"channels\": 3,\n",
    "            \"format\": \"RGB\",\n",
    "            \"normalization\": \"0-255\"\n",
    "        },\n",
    "        \"output_specifications\": {\n",
    "            \"detection_boxes\": \"N boxes with coordinates\",\n",
    "            \"detection_classes\": \"Class IDs (1: healthy, 2: contaminated)\",\n",
    "            \"detection_scores\": \"Confidence scores 0-1\",\n",
    "            \"num_detections\": \"Number of valid detections\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Sauvegarder les mÃ©tadonnÃ©es\n",
    "    metadata_path = os.path.join(destination_path, \"metadata.json\")\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… MÃ©tadonnÃ©es sauvegardÃ©es: {metadata_path}\")\n",
    "    \n",
    "    # Copier le label_map.pbtxt si disponible\n",
    "    label_map_source = \"/home/sarsator/projets/gaia_vision/training/models/dl_model/outputs/ssd_mnv2_320/label_map.pbtxt\"\n",
    "    if os.path.exists(label_map_source):\n",
    "        label_map_dest = os.path.join(destination_path, \"label_map.pbtxt\")\n",
    "        shutil.copy2(label_map_source, label_map_dest)\n",
    "        print(f\"âœ… Label map copiÃ©: {label_map_dest}\")\n",
    "    \n",
    "    return destination_path, metadata\n",
    "\n",
    "print(\"ğŸ¯ PrÃªt pour le dÃ©ploiement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3aa9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ DÃ‰MARRAGE DU DÃ‰PLOIEMENT AUTOMATIQUE\n",
      "============================================================\n",
      "ğŸš€ DÃ©ploiement vers: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518\n",
      "ğŸ“ Copie du modÃ¨le SavedModel...\n",
      "âœ… ModÃ¨le copiÃ© vers: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518/saved_model\n",
      "âœ… MÃ©tadonnÃ©es sauvegardÃ©es: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518/metadata.json\n",
      "âœ… Label map copiÃ©: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518/label_map.pbtxt\n",
      "\n",
      "============================================================\n",
      "âœ… DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS!\n",
      "============================================================\n",
      "ğŸ“ ModÃ¨le dÃ©ployÃ© dans: /home/sarsator/projets/gaia_vision/api/models/dl_model/versions/v1.3_20250716_132518\n",
      "ğŸ·ï¸  Version: v1.3_20250716_132518\n",
      "ğŸ“ Taille: 22.83 MB\n",
      "ğŸ—ï¸  Architecture: SSD_MobileNet_V2_320x320\n",
      "âš¡ Performance: F1-Score 97.9% | PrÃ©cision 99.8% | Rappel 96.0%\n",
      "ğŸ• Temps d'infÃ©rence: 16ms par image\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ EXÃ‰CUTION DU DÃ‰PLOIEMENT\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ DÃ‰MARRAGE DU DÃ‰PLOIEMENT AUTOMATIQUE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if model_info is not None:\n",
    "    # DÃ©ployer le modÃ¨le\n",
    "    deployed_path, metadata = deploy_model(next_version, next_timestamp, model_info)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“ ModÃ¨le dÃ©ployÃ© dans: {deployed_path}\")\n",
    "    print(f\"ğŸ·ï¸  Version: v{next_version}_{next_timestamp}\")\n",
    "    print(f\"ğŸ“ Taille: {model_info['size_mb']} MB\")\n",
    "    print(f\"ğŸ—ï¸  Architecture: {model_info['architecture']}\")\n",
    "    print(f\"âš¡ Performance: F1-Score 97.9% | PrÃ©cision 99.8% | Rappel 96.0%\")\n",
    "    print(f\"ğŸ• Temps d'infÃ©rence: 16ms par image\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Ã‰chec de l'analyse du modÃ¨le - DÃ©ploiement annulÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e593e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” VALIDATION DU DÃ‰PLOIEMENT\n",
      "----------------------------------------\n",
      "   âœ… Dossier de dÃ©ploiement crÃ©Ã©\n",
      "   âœ… SavedModel prÃ©sent\n",
      "   âœ… saved_model.pb prÃ©sent\n",
      "   âœ… variables prÃ©sent\n",
      "   âœ… MÃ©tadonnÃ©es prÃ©sentes\n",
      "   âœ… MÃ©tadonnÃ©es valides\n",
      "   âœ… Label map prÃ©sente\n",
      "   âœ… ModÃ¨le chargeable\n",
      "   âœ… Signature d'infÃ©rence disponible\n",
      "\n",
      "ğŸ“Š RÃ©sultat: 9/9 vÃ©rifications rÃ©ussies\n",
      "ğŸ‰ VALIDATION RÃ‰USSIE - ModÃ¨le prÃªt pour l'utilisation!\n"
     ]
    }
   ],
   "source": [
    "def validate_deployment(deployed_path):\n",
    "    \"\"\"Valide que le dÃ©ploiement s'est bien dÃ©roulÃ©\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ” VALIDATION DU DÃ‰PLOIEMENT\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # VÃ©rifier que le dossier existe\n",
    "    if os.path.exists(deployed_path):\n",
    "        checks.append(\"âœ… Dossier de dÃ©ploiement crÃ©Ã©\")\n",
    "    else:\n",
    "        checks.append(\"âŒ Dossier de dÃ©ploiement manquant\")\n",
    "        return False\n",
    "    \n",
    "    # VÃ©rifier le modÃ¨le SavedModel\n",
    "    saved_model_path = os.path.join(deployed_path, \"saved_model\")\n",
    "    if os.path.exists(saved_model_path):\n",
    "        checks.append(\"âœ… SavedModel prÃ©sent\")\n",
    "        \n",
    "        # VÃ©rifier les fichiers critiques\n",
    "        critical_files = [\"saved_model.pb\", \"variables\"]\n",
    "        for file in critical_files:\n",
    "            file_path = os.path.join(saved_model_path, file)\n",
    "            if os.path.exists(file_path):\n",
    "                checks.append(f\"âœ… {file} prÃ©sent\")\n",
    "            else:\n",
    "                checks.append(f\"âŒ {file} manquant\")\n",
    "    else:\n",
    "        checks.append(\"âŒ SavedModel manquant\")\n",
    "    \n",
    "    # VÃ©rifier les mÃ©tadonnÃ©es\n",
    "    metadata_path = os.path.join(deployed_path, \"metadata.json\")\n",
    "    if os.path.exists(metadata_path):\n",
    "        checks.append(\"âœ… MÃ©tadonnÃ©es prÃ©sentes\")\n",
    "        \n",
    "        # Tester le chargement du JSON\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            checks.append(\"âœ… MÃ©tadonnÃ©es valides\")\n",
    "        except:\n",
    "            checks.append(\"âŒ MÃ©tadonnÃ©es corrompues\")\n",
    "    else:\n",
    "        checks.append(\"âŒ MÃ©tadonnÃ©es manquantes\")\n",
    "    \n",
    "    # VÃ©rifier la label map\n",
    "    label_map_path = os.path.join(deployed_path, \"label_map.pbtxt\")\n",
    "    if os.path.exists(label_map_path):\n",
    "        checks.append(\"âœ… Label map prÃ©sente\")\n",
    "    else:\n",
    "        checks.append(\"âš ï¸  Label map manquante (optionnelle)\")\n",
    "    \n",
    "    # Test de chargement du modÃ¨le\n",
    "    try:\n",
    "        test_model = tf.saved_model.load(saved_model_path)\n",
    "        checks.append(\"âœ… ModÃ¨le chargeable\")\n",
    "        \n",
    "        # Test d'infÃ©rence rapide\n",
    "        if 'serving_default' in test_model.signatures:\n",
    "            checks.append(\"âœ… Signature d'infÃ©rence disponible\")\n",
    "        else:\n",
    "            checks.append(\"âš ï¸  Signature 'serving_default' non trouvÃ©e\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        checks.append(f\"âŒ Erreur de chargement: {str(e)[:50]}...\")\n",
    "    \n",
    "    # Afficher les rÃ©sultats\n",
    "    for check in checks:\n",
    "        print(f\"   {check}\")\n",
    "    \n",
    "    # Compter les succÃ¨s\n",
    "    success_count = sum(1 for check in checks if check.startswith(\"âœ…\"))\n",
    "    total_count = len([c for c in checks if not c.startswith(\"âš ï¸\")])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RÃ©sultat: {success_count}/{total_count} vÃ©rifications rÃ©ussies\")\n",
    "    \n",
    "    if success_count >= total_count * 0.8:  # 80% de rÃ©ussite minimum\n",
    "        print(\"ğŸ‰ VALIDATION RÃ‰USSIE - ModÃ¨le prÃªt pour l'utilisation!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"âŒ VALIDATION Ã‰CHOUÃ‰E - VÃ©rifier les erreurs ci-dessus\")\n",
    "        return False\n",
    "\n",
    "# ExÃ©cuter la validation si le dÃ©ploiement a rÃ©ussi\n",
    "if 'deployed_path' in locals():\n",
    "    validation_success = validate_deployment(deployed_path)\n",
    "else:\n",
    "    print(\"âš ï¸  Aucun dÃ©ploiement Ã  valider\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
