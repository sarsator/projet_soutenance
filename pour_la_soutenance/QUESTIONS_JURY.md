# üé§ Questions Probables du Jury - Soutenance GaiaSense Vision

## üß† Questions Techniques - Machine Learning & Deep Learning

### üî• Deep Learning (SSD MobileNet V2)

**Q1 : "Pourquoi avoir choisi SSD MobileNet V2 plut√¥t que YOLO ou R-CNN ?"**
- **R√©ponse** : SSD utilise un CNN (MobileNet V2) comme backbone avec des couches de d√©tection multi-√©chelles. MobileNet V2 est optimis√© pour la production (l√©ger, rapide). SSD offre un bon compromis vitesse/pr√©cision avec d√©tection en une seule passe, contrairement √† R-CNN qui n√©cessite plusieurs passes.

**Q2 : "Comment avez-vous g√©r√© l'overfitting avec si peu de donn√©es ?"**
- **R√©ponse** : Transfer learning depuis un mod√®le pr√©-entra√Æn√©, data augmentation, early stopping, dropout dans les couches finales.

**Q3 : "60% de F1-Score, c'est suffisant pour un syst√®me de production ?"**
- **R√©ponse** : Pour un prototype oui, c'est un bon point de d√©part. Am√©lioration possible avec plus de donn√©es annot√©es, fine-tuning plus pouss√©, ou ensemble de mod√®les.

**Q4 : "Expliquez-moi le processus de Transfer Learning que vous avez utilis√©."**
- **R√©ponse** : Mod√®le pr√©-entra√Æn√© sur COCO ‚Üí gel des couches de base ‚Üí fine-tuning des couches de classification ‚Üí adaptation aux classes champignons.

**Q5 : "Quelles m√©triques avez-vous utilis√©es pour √©valuer votre mod√®le de vision ?"**
- **R√©ponse** : F1-Score, Pr√©cision, Rappel avec sklearn.metrics, IoU pour les bounding boxes, courbes de loss dans TensorBoard.

**Q5bis : "Expliquez-moi l'architecture SSD MobileNet V2 que vous utilisez."**
- **R√©ponse** : SSD = Single Shot Detector utilise un CNN (MobileNet V2) comme backbone pour extraire les features, puis ajoute des couches de d√©tection multi-√©chelles pour pr√©dire les bounding boxes et classes en une seule passe. MobileNet V2 utilise des blocs r√©siduels invers√©s avec convolutions s√©parables pour √™tre l√©ger et rapide.

**Q5ter : "Pourquoi avoir choisi 320x320 comme taille d'image pour SSD ?"**
- **R√©ponse** : C'est la taille standard du checkpoint pr√©-entra√Æn√© SSD MobileNet V2 sur COCO. 320x320 offre un bon compromis entre pr√©cision et vitesse d'inf√©rence (~150ms). Plus petit (224x224) serait plus rapide mais moins pr√©cis, plus grand (640x640) plus pr√©cis mais plus lent.

**Q5quater : "Comment avez-vous g√©r√© la conversion CSV vers TFRecord ?"**
- **R√©ponse** : J'ai cr√©√© une fonction `create_tf_example` qui lit chaque ligne du CSV d'annotations, charge l'image correspondante, normalise les coordonn√©es des bounding boxes (0-1), et cr√©e un exemple TFRecord avec toutes les m√©tadonn√©es n√©cessaires pour l'entra√Ænement SSD.

**Q5quinquies : "Qu'est-ce que TensorBoard vous a apport√© dans ce projet ?"**
- **R√©ponse** : TensorBoard m'a permis de monitorer l'entra√Ænement en temps r√©el : courbes de loss, m√©triques de validation, visualisation des images avec bounding boxes, et debugging des probl√®mes de convergence. Essential pour ajuster les hyperparam√®tres.

### üê± Machine Learning (CatBoost)

**Q6 : "Pourquoi CatBoost plut√¥t que Random Forest ou XGBoost ?"**
- **R√©ponse** : CatBoost g√®re naturellement les variables cat√©gorielles sans encoding, plus robuste aux outliers, moins de preprocessing requis.

**Q7 : "Comment avez-vous valid√© votre mod√®le CatBoost ?"**
- **R√©ponse** : Validation crois√©e K-fold, split temporel si donn√©es temporelles, m√©triques de stabilit√©, feature importance.

**Q8 : "Quelles sont les features les plus importantes dans votre mod√®le ?"**
- **R√©ponse** : Dans mon mod√®le CatBoost, les features les plus importantes sont le type de champignon, le substrat, et le jour d'inoculation. J'ai utilis√© l'analyse feature_importance de CatBoost pour identifier ces variables cl√©s.

**Q8bis : "Pourquoi 1200 iterations pour CatBoost ?"**
- **R√©ponse** : J'ai test√© diff√©rentes valeurs et utilis√© l'early stopping avec 20 rounds. 1200 iterations avec learning_rate=0.1 et depth=3 donnait le meilleur compromis performance/temps sur GPU. L'early stopping √©vite l'overfitting.

**Q8ter : "Comment avez-vous g√©r√© les variables cat√©gorielles dans CatBoost ?"**
- **R√©ponse** : CatBoost g√®re nativement les variables cat√©gorielles sans preprocessing. J'ai d√©fini cat_features=["champignon", "substrat", "Jour_inoculation"] et CatBoost applique automatiquement son algorithme de target encoding optimis√©.

**Q8quater : "Quelle diff√©rence entre le format .cbm et .joblib pour sauvegarder CatBoost ?"**
- **R√©ponse** : .cbm est le format natif CatBoost (plus compact, chargement plus rapide), .joblib est plus universel pour l'int√©gration avec d'autres outils Python. J'ai sauvegard√© les deux pour plus de flexibilit√© dans l'API.

**Q9 : "85% d'accuracy, comment √™tre s√ªr que ce n'est pas du data leakage ?"**
- **R√©ponse** : Split strict train/validation/test, pas de preprocessing avant split, validation crois√©e, v√©rification des corr√©lations.

## üèóÔ∏è Questions Architecture & Technique

### üîß Architecture Syst√®me

**Q10 : "Pourquoi avoir choisi une architecture hybride DL + ML ?"**
- **R√©ponse** : Exploite les forces de chaque approche : DL pour les images, ML pour les donn√©es tabulaires. Modularit√© et possibilit√© d'√©volution ind√©pendante.

**Q11 : "Comment vos deux mod√®les communiquent-ils ?"**
- **R√©ponse** : API REST avec FastAPI, chaque mod√®le est un service ind√©pendant, orchestration via l'API centrale.

**Q12 : "Que se passe-t-il si un des mod√®les tombe en panne ?"**
- **R√©ponse** : Syst√®me de fallback, mode d√©grad√©, gestion d'erreurs, monitoring des services.

**Q13 : "Comment g√©rez-vous les mont√©es en charge ?"**
- **R√©ponse** : Architecture modulaire, possibilit√© de scale horizontalement, cache des pr√©dictions, optimisation des mod√®les.

### üöÄ D√©ploiement & Production

**Q14 : "Votre syst√®me est-il pr√™t pour la production ?"**
- **R√©ponse** : Prototype avanc√© avec architecture production-ready, gestion d'erreurs, logging, versioning. N√©cessite monitoring et tests de charge.

**Q15 : "Comment g√©rez-vous les nouvelles versions de mod√®les ?"**
- **R√©ponse** : Syst√®me de versioning automatique, rollback possible, tests A/B, d√©ploiement graduel.

**Q16 : "Quelles sont les vuln√©rabilit√©s de s√©curit√© potentielles ?"**
- **R√©ponse** : Validation des inputs, authentification API, chiffrement des donn√©es, limite de taille des uploads.

## üí° Questions M√©thodologiques

### üìä Donn√©es & Preprocessing

**Q17 : "Comment avez-vous constitu√© votre dataset ?"**
- **R√©ponse** : Partenariat avec CENTER FOR AGRIC-BUSINESS INNOVATIONS, photos r√©elles terrain, annotation manuelle, √©quilibrage des classes.

**Q18 : "Quelles techniques de data augmentation avez-vous utilis√©es ?"**
- **R√©ponse** : Rotation, flip, zoom, changement de luminosit√©, bruit gaussien, pr√©servation des bounding boxes.

**Q19 : "Comment g√©rez-vous les donn√©es d√©s√©quilibr√©es ?"**
- **R√©ponse** : √âchantillonnage √©quilibr√©, weights dans la loss function, m√©triques adapt√©es (F1-Score vs Accuracy).

### üîç Validation & Testing

**Q20 : "Comment avez-vous split√© vos donn√©es ?"**
- **R√©ponse** : Split stratifi√© 70/15/15 train/validation/test, attention aux donn√©es temporelles si applicable.

**Q21 : "Avez-vous test√© d'autres architectures ?"**
- **R√©ponse** : J'ai d'abord explor√© diff√©rentes options : YOLO (plus rapide mais moins pr√©cis), R-CNN (plus pr√©cis mais plus lent), EfficientNet (bon compromis mais plus complexe √† d√©ployer). J'ai choisi SSD MobileNet V2 pour l'√©quilibre performance/vitesse/taille.

**Q21bis : "Comment avez-vous configur√© votre pipeline d'entra√Ænement ?"**
- **R√©ponse** : J'ai utilis√© 30k steps (~40 epochs), batch_size=16 (optimis√© pour RTX 4080), learning_rate=0.02 avec cosine schedule, et warmup_steps=1500. Configuration dans un fichier pipeline.config pour TensorFlow Object Detection API.

**Q21ter : "Pourquoi avoir choisi un batch_size de 16 ?"**
- **R√©ponse** : C'est optimis√© pour ma GPU RTX 4080. J'ai test√© diff√©rentes valeurs : 8 (sous-utilise la GPU), 32 (out of memory), 16 donne le meilleur compromis vitesse/stabilit√© d'entra√Ænement avec images 320x320.

**Q21quater : "Comment avez-vous g√©r√© le Transfer Learning ?"**
- **R√©ponse** : J'ai utilis√© un checkpoint pr√©-entra√Æn√© sur COCO, gel√© les couches backbone, et fine-tun√© seulement les couches de classification sur mes 2 classes (Healthy/Contaminated). Cela acc√©l√®re l'entra√Ænement et am√©liore la g√©n√©ralisation.

**Q22 : "Comment savez-vous que votre mod√®le g√©n√©ralise bien ?"**
- **R√©ponse** : Test sur donn√©es jamais vues, validation crois√©e, m√©triques sur diff√©rents sous-ensembles.

## üéØ Questions Business & Impact

### üíº Valeur Ajout√©e

**Q23 : "Quelle est la valeur business de votre solution ?"**
- **R√©ponse** : Automatisation d√©tection, r√©duction erreurs humaines, scalabilit√©, tra√ßabilit√©, aide √† la d√©cision.

**Q24 : "Qui sont vos utilisateurs cibles ?"**
- **R√©ponse** : Agriculteurs, centres de recherche agricole, coop√©ratives, inspecteurs qualit√©.

**Q25 : "Quel est le ROI estim√© de votre solution ?"**
- **R√©ponse** : [√Ä adapter] R√©duction temps inspection, diminution pertes, am√©lioration qualit√© produits.

### üîÆ √âvolutions & Limitations

**Q26 : "Quelles sont les limites actuelles de votre syst√®me ?"**
- **R√©ponse** : Pr√©cision perfectible, dataset limit√©, environnement contr√¥l√©, pas de temps r√©el strict.

**Q27 : "Comment voyez-vous l'√©volution future du projet ?"**
- **R√©ponse** : Plus de donn√©es, mod√®les plus complexes, d√©ploiement cloud, mobile app, IoT int√©gration.

**Q28 : "Que feriez-vous diff√©remment si c'√©tait √† refaire ?"**
- **R√©ponse** : Plus de donn√©es d√®s le d√©but, tests A/B, architecture microservices, monitoring avanc√©.

## üéì Questions P√©dagogiques

### üìö Apprentissage & Comp√©tences

**Q29 : "Qu'avez-vous appris de plus important dans ce projet ?"**
- **R√©ponse** : Importance de l'architecture, choix techniques justifi√©s, cycle complet ML/DL, contraintes production.

**Q30 : "Quelles ont √©t√© vos principales difficult√©s ?"**
- **R√©ponse** : Donn√©es limit√©es, optimisation performances, d√©ploiement, debugging.

**Q31 : "Comment vous √™tes-vous form√© sur ces technologies ?"**
- **R√©ponse** : Formation Alyra, documentation officielle, projets pratiques, communaut√©, youtube, intelligence artificiel.

### üî¨ M√©thodes & Outils

**Q32 : "Quels outils avez-vous utilis√©s pour le d√©veloppement ?"**
- **R√©ponse** : Jupyter notebooks, TensorBoard, Git, VS Code, .

**Q33 : "Comment avez-vous g√©r√© le versioning de votre code ?"**
- **R√©ponse** : Git avec branches features, commits atomiques, documentation, tests avant merge. 

**Q34 : "Avez-vous fait des tests unitaires ?"**
- **R√©ponse** : Tests sur les fonctions critiques, validation des inputs/outputs, tests d'int√©gration API.

## ü§î Questions Pi√®ges Potentielles

### ‚ö†Ô∏è Questions Critiques

**Q35 : "Votre F1-Score de 60% n'est-il pas trop faible ?"**
- **R√©ponse** : Pour un prototype avec donn√©es limit√©es, c'est acceptable. Am√©lioration possible avec plus de donn√©es et fine-tuning.

**Q36 : "Pourquoi pas utiliser une solution existante comme Google Vision API ?"**
- **R√©ponse** : Sp√©cificit√© du domaine agricole, contr√¥le total, co√ªt √† long terme, apprentissage technique.

**Q37 : "N'auriez-vous pas pu faire plus simple avec juste un mod√®le ?"**
- **R√©ponse** : Approche hybride justifi√©e par la nature diff√©rente des donn√©es (images vs tabulaires), meilleure modularit√©.

**Q38 : "Comment √™tre s√ªr que votre mod√®le ne discrimine pas ?"**
- **R√©ponse** : Validation sur diff√©rents sous-groupes, m√©triques de fairness, dataset √©quilibr√©.

**Q39 : "Avec seulement 2 classes, √©tait-ce vraiment n√©cessaire d'utiliser SSD ?"**
- **R√©ponse** : SSD ne fait pas que classifier, il fait de la d√©tection d'objets avec localisation. M√™me avec 2 classes, il faut d√©tecter ET localiser les champignons dans l'image avec des bounding boxes.

**Q40 : "Pourquoi TensorFlow Object Detection API au lieu de PyTorch ?"**
- **R√©ponse** : TensorFlow OD API offre des checkpoints pr√©-entra√Æn√©s compatibles, pipeline.config standardis√©, et TensorBoard int√©gr√©. Plus mature pour la d√©tection d'objets en production.

**Q41 : "Votre dataset est-il assez grand pour √©viter l'overfitting ?"**
- **R√©ponse** : J'ai utilis√© transfer learning, data augmentation, early stopping, et validation crois√©e. Le mod√®le g√©n√©ralise bien sur le test set gr√¢ce √† ces techniques de r√©gularisation.

**Q42 : "Comment justifier le choix des hyperparam√®tres CatBoost ?"**
- **R√©ponse** : depth=3 √©vite l'overfitting, iterations=1200 avec early stopping trouve le bon √©quilibre, learning_rate=0.1 sur GPU donne une convergence stable. J'ai test√© diff√©rentes combinaisons.

---

## üí° Conseils pour R√©pondre

### ‚úÖ Bonnes Pratiques
- **Soyez honn√™te** sur les limitations
- **Justifiez vos choix** techniques
- **Donnez des exemples concrets**
- **Montrez votre compr√©hension** des enjeux
- **Pr√©parez des sch√©mas** si n√©cessaire

### ‚ùå √Ä √âviter
- R√©ponses vagues ou √©vasives
- "Je ne sais pas" sans proposition
- Sur-vendre les performances
- Ignorer les limitations
- R√©ponses trop techniques sans contexte

---

## üéØ Questions √† Poser au Jury

**En fin de soutenance, vous pouvez poser :**
- "Auriez-vous fait des choix diff√©rents ?"
- "Que pensez-vous du potentiel de cette approche ?"
- "Quels domaines me conseillez-vous d'approfondir ?"

---

*Pr√©par√© pour la soutenance Alyra - 2025*
*Bonne chance ! üçÄ*
